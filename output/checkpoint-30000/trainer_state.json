{
  "best_metric": 67.73754020879127,
  "best_model_checkpoint": "output/checkpoint-29000",
  "epoch": 129.20592193808884,
  "eval_steps": 1000,
  "global_step": 30000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.4306864064602961,
      "grad_norm": 1.701179027557373,
      "learning_rate": 5e-06,
      "loss": 5.125,
      "num_input_tokens_seen": 203872,
      "step": 100
    },
    {
      "epoch": 0.8613728129205922,
      "grad_norm": 2.3627851009368896,
      "learning_rate": 1e-05,
      "loss": 4.6606,
      "num_input_tokens_seen": 406976,
      "step": 200
    },
    {
      "epoch": 1.2920592193808882,
      "grad_norm": 0.576862633228302,
      "learning_rate": 1.5e-05,
      "loss": 3.4913,
      "num_input_tokens_seen": 613656,
      "step": 300
    },
    {
      "epoch": 1.7227456258411844,
      "grad_norm": 0.4405195415019989,
      "learning_rate": 2e-05,
      "loss": 2.9889,
      "num_input_tokens_seen": 816792,
      "step": 400
    },
    {
      "epoch": 2.1534320323014806,
      "grad_norm": 0.37419113516807556,
      "learning_rate": 2.5e-05,
      "loss": 2.6069,
      "num_input_tokens_seen": 1020976,
      "step": 500
    },
    {
      "epoch": 2.5841184387617764,
      "grad_norm": 0.4175524413585663,
      "learning_rate": 3e-05,
      "loss": 2.4343,
      "num_input_tokens_seen": 1224432,
      "step": 600
    },
    {
      "epoch": 3.0148048452220726,
      "grad_norm": 0.3354434669017792,
      "learning_rate": 3.5e-05,
      "loss": 2.3478,
      "num_input_tokens_seen": 1427688,
      "step": 700
    },
    {
      "epoch": 3.445491251682369,
      "grad_norm": 0.39046090841293335,
      "learning_rate": 4e-05,
      "loss": 2.2189,
      "num_input_tokens_seen": 1631112,
      "step": 800
    },
    {
      "epoch": 3.876177658142665,
      "grad_norm": 0.39334172010421753,
      "learning_rate": 4.5e-05,
      "loss": 2.1035,
      "num_input_tokens_seen": 1833736,
      "step": 900
    },
    {
      "epoch": 4.306864064602961,
      "grad_norm": 0.5705759525299072,
      "learning_rate": 5e-05,
      "loss": 2.0168,
      "num_input_tokens_seen": 2038912,
      "step": 1000
    },
    {
      "epoch": 4.306864064602961,
      "eval_BLEU": 3.8122341012643473,
      "eval_chrF": 36.43280946301253,
      "eval_loss": 2.019329071044922,
      "eval_runtime": 9134.4198,
      "eval_samples_per_second": 3.254,
      "eval_steps_per_second": 0.813,
      "num_input_tokens_seen": 2038912,
      "step": 1000
    },
    {
      "epoch": 4.737550471063257,
      "grad_norm": 0.5001136660575867,
      "learning_rate": 5.500000000000001e-05,
      "loss": 2.0445,
      "num_input_tokens_seen": 2241920,
      "step": 1100
    },
    {
      "epoch": 5.168236877523553,
      "grad_norm": 0.7218773365020752,
      "learning_rate": 6e-05,
      "loss": 1.9738,
      "num_input_tokens_seen": 2445976,
      "step": 1200
    },
    {
      "epoch": 5.598923283983849,
      "grad_norm": 0.6985712051391602,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.9574,
      "num_input_tokens_seen": 2649688,
      "step": 1300
    },
    {
      "epoch": 6.029609690444145,
      "grad_norm": 0.5494056940078735,
      "learning_rate": 7e-05,
      "loss": 1.9731,
      "num_input_tokens_seen": 2852656,
      "step": 1400
    },
    {
      "epoch": 6.460296096904441,
      "grad_norm": 0.5963790416717529,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.8964,
      "num_input_tokens_seen": 3056272,
      "step": 1500
    },
    {
      "epoch": 6.890982503364738,
      "grad_norm": 0.659528911113739,
      "learning_rate": 8e-05,
      "loss": 1.8906,
      "num_input_tokens_seen": 3258416,
      "step": 1600
    },
    {
      "epoch": 7.321668909825034,
      "grad_norm": 0.7196580171585083,
      "learning_rate": 8.5e-05,
      "loss": 1.7727,
      "num_input_tokens_seen": 3463272,
      "step": 1700
    },
    {
      "epoch": 7.75235531628533,
      "grad_norm": 0.7764711976051331,
      "learning_rate": 9e-05,
      "loss": 1.8272,
      "num_input_tokens_seen": 3666856,
      "step": 1800
    },
    {
      "epoch": 8.183041722745626,
      "grad_norm": 0.9047828316688538,
      "learning_rate": 9.5e-05,
      "loss": 1.8578,
      "num_input_tokens_seen": 3870528,
      "step": 1900
    },
    {
      "epoch": 8.613728129205922,
      "grad_norm": 0.9182494282722473,
      "learning_rate": 0.0001,
      "loss": 1.7839,
      "num_input_tokens_seen": 4073920,
      "step": 2000
    },
    {
      "epoch": 8.613728129205922,
      "eval_BLEU": 6.140892462109956,
      "eval_chrF": 42.39972027507838,
      "eval_loss": 1.7336806058883667,
      "eval_runtime": 6924.5283,
      "eval_samples_per_second": 4.292,
      "eval_steps_per_second": 1.073,
      "num_input_tokens_seen": 4073920,
      "step": 2000
    },
    {
      "epoch": 9.044414535666219,
      "grad_norm": 0.8307850956916809,
      "learning_rate": 0.000105,
      "loss": 1.7742,
      "num_input_tokens_seen": 4277016,
      "step": 2100
    },
    {
      "epoch": 9.475100942126515,
      "grad_norm": 0.8229411244392395,
      "learning_rate": 0.00011000000000000002,
      "loss": 1.7292,
      "num_input_tokens_seen": 4480888,
      "step": 2200
    },
    {
      "epoch": 9.90578734858681,
      "grad_norm": 1.0547361373901367,
      "learning_rate": 0.00011499999999999999,
      "loss": 1.7464,
      "num_input_tokens_seen": 4683384,
      "step": 2300
    },
    {
      "epoch": 10.336473755047106,
      "grad_norm": 0.9621979594230652,
      "learning_rate": 0.00012,
      "loss": 1.6566,
      "num_input_tokens_seen": 4888432,
      "step": 2400
    },
    {
      "epoch": 10.767160161507402,
      "grad_norm": 1.1656601428985596,
      "learning_rate": 0.000125,
      "loss": 1.6892,
      "num_input_tokens_seen": 5091984,
      "step": 2500
    },
    {
      "epoch": 11.197846567967698,
      "grad_norm": 1.2228089570999146,
      "learning_rate": 0.00013000000000000002,
      "loss": 1.7134,
      "num_input_tokens_seen": 5295496,
      "step": 2600
    },
    {
      "epoch": 11.628532974427994,
      "grad_norm": 1.32364821434021,
      "learning_rate": 0.00013500000000000003,
      "loss": 1.6609,
      "num_input_tokens_seen": 5499240,
      "step": 2700
    },
    {
      "epoch": 12.05921938088829,
      "grad_norm": 1.2049146890640259,
      "learning_rate": 0.00014,
      "loss": 1.6332,
      "num_input_tokens_seen": 5702432,
      "step": 2800
    },
    {
      "epoch": 12.489905787348587,
      "grad_norm": 1.0890871286392212,
      "learning_rate": 0.000145,
      "loss": 1.5769,
      "num_input_tokens_seen": 5905856,
      "step": 2900
    },
    {
      "epoch": 12.920592193808883,
      "grad_norm": 1.2266361713409424,
      "learning_rate": 0.00015000000000000001,
      "loss": 1.6332,
      "num_input_tokens_seen": 6108288,
      "step": 3000
    },
    {
      "epoch": 12.920592193808883,
      "eval_BLEU": 15.973661356987577,
      "eval_chrF": 52.84067681575597,
      "eval_loss": 1.5450592041015625,
      "eval_runtime": 3043.8758,
      "eval_samples_per_second": 9.764,
      "eval_steps_per_second": 2.441,
      "num_input_tokens_seen": 6108288,
      "step": 3000
    },
    {
      "epoch": 13.351278600269179,
      "grad_norm": 1.2481393814086914,
      "learning_rate": 0.000155,
      "loss": 1.5339,
      "num_input_tokens_seen": 6312952,
      "step": 3100
    },
    {
      "epoch": 13.781965006729475,
      "grad_norm": 1.2295877933502197,
      "learning_rate": 0.00016,
      "loss": 1.576,
      "num_input_tokens_seen": 6516664,
      "step": 3200
    },
    {
      "epoch": 14.212651413189771,
      "grad_norm": 1.7779520750045776,
      "learning_rate": 0.000165,
      "loss": 1.6042,
      "num_input_tokens_seen": 6717456,
      "step": 3300
    },
    {
      "epoch": 14.643337819650068,
      "grad_norm": 2.058474063873291,
      "learning_rate": 0.00017,
      "loss": 1.5447,
      "num_input_tokens_seen": 6921104,
      "step": 3400
    },
    {
      "epoch": 15.074024226110364,
      "grad_norm": 1.130005121231079,
      "learning_rate": 0.000175,
      "loss": 1.5009,
      "num_input_tokens_seen": 7127208,
      "step": 3500
    },
    {
      "epoch": 15.50471063257066,
      "grad_norm": 1.3730303049087524,
      "learning_rate": 0.00018,
      "loss": 1.4704,
      "num_input_tokens_seen": 7330536,
      "step": 3600
    },
    {
      "epoch": 15.935397039030956,
      "grad_norm": 1.302757740020752,
      "learning_rate": 0.00018500000000000002,
      "loss": 1.505,
      "num_input_tokens_seen": 7533128,
      "step": 3700
    },
    {
      "epoch": 16.366083445491252,
      "grad_norm": 1.5146578550338745,
      "learning_rate": 0.00019,
      "loss": 1.4405,
      "num_input_tokens_seen": 7738080,
      "step": 3800
    },
    {
      "epoch": 16.79676985195155,
      "grad_norm": 1.5347174406051636,
      "learning_rate": 0.000195,
      "loss": 1.479,
      "num_input_tokens_seen": 7941728,
      "step": 3900
    },
    {
      "epoch": 17.227456258411845,
      "grad_norm": 1.137338638305664,
      "learning_rate": 0.0002,
      "loss": 1.5005,
      "num_input_tokens_seen": 8144952,
      "step": 4000
    },
    {
      "epoch": 17.227456258411845,
      "eval_BLEU": 12.800747168424515,
      "eval_chrF": 53.59983240106829,
      "eval_loss": 1.3618903160095215,
      "eval_runtime": 3497.7432,
      "eval_samples_per_second": 8.497,
      "eval_steps_per_second": 2.124,
      "num_input_tokens_seen": 8144952,
      "step": 4000
    },
    {
      "epoch": 17.65814266487214,
      "grad_norm": 1.1301511526107788,
      "learning_rate": 0.00019754591932991794,
      "loss": 1.4222,
      "num_input_tokens_seen": 8347864,
      "step": 4100
    },
    {
      "epoch": 18.088829071332437,
      "grad_norm": 1.3690111637115479,
      "learning_rate": 0.00019518001458970662,
      "loss": 1.3794,
      "num_input_tokens_seen": 8552176,
      "step": 4200
    },
    {
      "epoch": 18.519515477792734,
      "grad_norm": 1.3094570636749268,
      "learning_rate": 0.00019289712886816487,
      "loss": 1.3799,
      "num_input_tokens_seen": 8755376,
      "step": 4300
    },
    {
      "epoch": 18.95020188425303,
      "grad_norm": 1.403018832206726,
      "learning_rate": 0.00019069251784911847,
      "loss": 1.4015,
      "num_input_tokens_seen": 8958000,
      "step": 4400
    },
    {
      "epoch": 19.380888290713326,
      "grad_norm": 2.004037380218506,
      "learning_rate": 0.0001885618083164127,
      "loss": 1.3189,
      "num_input_tokens_seen": 9163080,
      "step": 4500
    },
    {
      "epoch": 19.81157469717362,
      "grad_norm": 1.7128154039382935,
      "learning_rate": 0.00018650096164806276,
      "loss": 1.3595,
      "num_input_tokens_seen": 9366504,
      "step": 4600
    },
    {
      "epoch": 20.242261103633915,
      "grad_norm": 1.3525723218917847,
      "learning_rate": 0.00018450624160577702,
      "loss": 1.3538,
      "num_input_tokens_seen": 9570144,
      "step": 4700
    },
    {
      "epoch": 20.67294751009421,
      "grad_norm": 1.2210636138916016,
      "learning_rate": 0.0001825741858350554,
      "loss": 1.3156,
      "num_input_tokens_seen": 9773376,
      "step": 4800
    },
    {
      "epoch": 21.103633916554507,
      "grad_norm": 1.6344140768051147,
      "learning_rate": 0.00018070158058105027,
      "loss": 1.2594,
      "num_input_tokens_seen": 9976952,
      "step": 4900
    },
    {
      "epoch": 21.534320323014803,
      "grad_norm": 1.5825331211090088,
      "learning_rate": 0.00017888543819998318,
      "loss": 1.2537,
      "num_input_tokens_seen": 10180920,
      "step": 5000
    },
    {
      "epoch": 21.534320323014803,
      "eval_BLEU": 17.32552941711246,
      "eval_chrF": 57.53860686246347,
      "eval_loss": 1.1931277513504028,
      "eval_runtime": 2955.5788,
      "eval_samples_per_second": 10.055,
      "eval_steps_per_second": 2.514,
      "num_input_tokens_seen": 10180920,
      "step": 5000
    },
    {
      "epoch": 21.9650067294751,
      "grad_norm": 1.791204810142517,
      "learning_rate": 0.00017712297710801908,
      "loss": 1.3061,
      "num_input_tokens_seen": 10382968,
      "step": 5100
    },
    {
      "epoch": 22.395693135935396,
      "grad_norm": 1.7956479787826538,
      "learning_rate": 0.00017541160386140586,
      "loss": 1.2253,
      "num_input_tokens_seen": 10587920,
      "step": 5200
    },
    {
      "epoch": 22.826379542395692,
      "grad_norm": 1.87252938747406,
      "learning_rate": 0.00017374889710522777,
      "loss": 1.2342,
      "num_input_tokens_seen": 10791280,
      "step": 5300
    },
    {
      "epoch": 23.25706594885599,
      "grad_norm": 1.4286614656448364,
      "learning_rate": 0.00017213259316477408,
      "loss": 1.2304,
      "num_input_tokens_seen": 10994600,
      "step": 5400
    },
    {
      "epoch": 23.687752355316285,
      "grad_norm": 1.5421695709228516,
      "learning_rate": 0.00017056057308448833,
      "loss": 1.2004,
      "num_input_tokens_seen": 11197832,
      "step": 5500
    },
    {
      "epoch": 24.11843876177658,
      "grad_norm": 1.8411788940429688,
      "learning_rate": 0.00016903085094570333,
      "loss": 1.1713,
      "num_input_tokens_seen": 11401728,
      "step": 5600
    },
    {
      "epoch": 24.549125168236877,
      "grad_norm": 1.714586615562439,
      "learning_rate": 0.00016754156331667822,
      "loss": 1.1707,
      "num_input_tokens_seen": 11604832,
      "step": 5700
    },
    {
      "epoch": 24.979811574697173,
      "grad_norm": 1.7752598524093628,
      "learning_rate": 0.00016609095970747994,
      "loss": 1.2133,
      "num_input_tokens_seen": 11807648,
      "step": 5800
    },
    {
      "epoch": 25.41049798115747,
      "grad_norm": 1.9991991519927979,
      "learning_rate": 0.00016467739391852365,
      "loss": 1.1125,
      "num_input_tokens_seen": 12012664,
      "step": 5900
    },
    {
      "epoch": 25.841184387617766,
      "grad_norm": 1.9995514154434204,
      "learning_rate": 0.00016329931618554524,
      "loss": 1.1556,
      "num_input_tokens_seen": 12216312,
      "step": 6000
    },
    {
      "epoch": 25.841184387617766,
      "eval_BLEU": 6.88972965925764,
      "eval_chrF": 50.624489459031,
      "eval_loss": 1.050746202468872,
      "eval_runtime": 7584.8544,
      "eval_samples_per_second": 3.918,
      "eval_steps_per_second": 0.98,
      "num_input_tokens_seen": 12216312,
      "step": 6000
    },
    {
      "epoch": 26.271870794078062,
      "grad_norm": 1.8837848901748657,
      "learning_rate": 0.00016195526603578322,
      "loss": 1.1266,
      "num_input_tokens_seen": 12419408,
      "step": 6100
    },
    {
      "epoch": 26.702557200538358,
      "grad_norm": 1.4847583770751953,
      "learning_rate": 0.00016064386578049978,
      "loss": 1.1063,
      "num_input_tokens_seen": 12622544,
      "step": 6200
    },
    {
      "epoch": 27.133243606998654,
      "grad_norm": 1.8079134225845337,
      "learning_rate": 0.00015936381457791915,
      "loss": 1.0669,
      "num_input_tokens_seen": 12826504,
      "step": 6300
    },
    {
      "epoch": 27.56393001345895,
      "grad_norm": 2.031217336654663,
      "learning_rate": 0.00015811388300841897,
      "loss": 1.0857,
      "num_input_tokens_seen": 13030120,
      "step": 6400
    },
    {
      "epoch": 27.994616419919247,
      "grad_norm": 2.965177297592163,
      "learning_rate": 0.00015689290811054724,
      "loss": 1.1571,
      "num_input_tokens_seen": 13231656,
      "step": 6500
    },
    {
      "epoch": 28.425302826379543,
      "grad_norm": 2.8897647857666016,
      "learning_rate": 0.0001556997888323046,
      "loss": 1.0559,
      "num_input_tokens_seen": 13435200,
      "step": 6600
    },
    {
      "epoch": 28.85598923283984,
      "grad_norm": 2.5745151042938232,
      "learning_rate": 0.00015453348185725117,
      "loss": 1.0635,
      "num_input_tokens_seen": 13638496,
      "step": 6700
    },
    {
      "epoch": 29.286675639300135,
      "grad_norm": 1.5488898754119873,
      "learning_rate": 0.00015339299776947408,
      "loss": 1.0178,
      "num_input_tokens_seen": 13844280,
      "step": 6800
    },
    {
      "epoch": 29.71736204576043,
      "grad_norm": 1.7955801486968994,
      "learning_rate": 0.0001522773975253762,
      "loss": 1.0415,
      "num_input_tokens_seen": 14047352,
      "step": 6900
    },
    {
      "epoch": 30.148048452220728,
      "grad_norm": 2.094613790512085,
      "learning_rate": 0.0001511857892036909,
      "loss": 0.9732,
      "num_input_tokens_seen": 14251248,
      "step": 7000
    },
    {
      "epoch": 30.148048452220728,
      "eval_BLEU": 33.338492109368794,
      "eval_chrF": 66.90934352332685,
      "eval_loss": 0.9279971122741699,
      "eval_runtime": 2279.3284,
      "eval_samples_per_second": 13.038,
      "eval_steps_per_second": 3.26,
      "num_input_tokens_seen": 14251248,
      "step": 7000
    },
    {
      "epoch": 30.578734858681024,
      "grad_norm": 1.865736722946167,
      "learning_rate": 0.00015011732500816032,
      "loss": 1.0102,
      "num_input_tokens_seen": 14454896,
      "step": 7100
    },
    {
      "epoch": 31.00942126514132,
      "grad_norm": 1.2109999656677246,
      "learning_rate": 0.00014907119849998598,
      "loss": 1.1009,
      "num_input_tokens_seen": 14657768,
      "step": 7200
    },
    {
      "epoch": 31.440107671601616,
      "grad_norm": 1.5130889415740967,
      "learning_rate": 0.00014804664203952106,
      "loss": 0.9732,
      "num_input_tokens_seen": 14861416,
      "step": 7300
    },
    {
      "epoch": 31.870794078061913,
      "grad_norm": 1.6439968347549438,
      "learning_rate": 0.00014704292441876157,
      "loss": 1.0091,
      "num_input_tokens_seen": 15064072,
      "step": 7400
    },
    {
      "epoch": 32.30148048452221,
      "grad_norm": 1.3424618244171143,
      "learning_rate": 0.00014605934866804428,
      "loss": 0.9194,
      "num_input_tokens_seen": 15269056,
      "step": 7500
    },
    {
      "epoch": 32.732166890982505,
      "grad_norm": 1.835135817527771,
      "learning_rate": 0.00014509525002200235,
      "loss": 0.9713,
      "num_input_tokens_seen": 15472544,
      "step": 7600
    },
    {
      "epoch": 33.1628532974428,
      "grad_norm": 2.223942279815674,
      "learning_rate": 0.00014414999403128943,
      "loss": 0.9364,
      "num_input_tokens_seen": 15676088,
      "step": 7700
    },
    {
      "epoch": 33.5935397039031,
      "grad_norm": 4.038457870483398,
      "learning_rate": 0.00014322297480788657,
      "loss": 0.9422,
      "num_input_tokens_seen": 15879608,
      "step": 7800
    },
    {
      "epoch": 34.024226110363394,
      "grad_norm": 1.5377708673477173,
      "learning_rate": 0.000142313613392964,
      "loss": 1.0167,
      "num_input_tokens_seen": 16082928,
      "step": 7900
    },
    {
      "epoch": 34.45491251682369,
      "grad_norm": 1.3731310367584229,
      "learning_rate": 0.0001414213562373095,
      "loss": 0.902,
      "num_input_tokens_seen": 16286736,
      "step": 8000
    },
    {
      "epoch": 34.45491251682369,
      "eval_BLEU": 39.14441766196189,
      "eval_chrF": 69.73574414555578,
      "eval_loss": 0.8359068632125854,
      "eval_runtime": 2293.9147,
      "eval_samples_per_second": 12.956,
      "eval_steps_per_second": 3.239,
      "num_input_tokens_seen": 16286736,
      "step": 8000
    },
    {
      "epoch": 34.885598923283986,
      "grad_norm": 1.6181068420410156,
      "learning_rate": 0.0001405456737852613,
      "loss": 0.9329,
      "num_input_tokens_seen": 16489040,
      "step": 8100
    },
    {
      "epoch": 35.31628532974428,
      "grad_norm": 1.777456283569336,
      "learning_rate": 0.00013968605915391566,
      "loss": 0.8827,
      "num_input_tokens_seen": 16693576,
      "step": 8200
    },
    {
      "epoch": 35.74697173620458,
      "grad_norm": 2.1017963886260986,
      "learning_rate": 0.00013884202690012468,
      "loss": 0.9009,
      "num_input_tokens_seen": 16896904,
      "step": 8300
    },
    {
      "epoch": 36.177658142664875,
      "grad_norm": 2.061311960220337,
      "learning_rate": 0.00013801311186847085,
      "loss": 0.9263,
      "num_input_tokens_seen": 17101152,
      "step": 8400
    },
    {
      "epoch": 36.60834454912517,
      "grad_norm": 2.4050357341766357,
      "learning_rate": 0.00013719886811400705,
      "loss": 0.9,
      "num_input_tokens_seen": 17304128,
      "step": 8500
    },
    {
      "epoch": 37.03903095558547,
      "grad_norm": 1.7090213298797607,
      "learning_rate": 0.0001363988678940947,
      "loss": 0.917,
      "num_input_tokens_seen": 17507544,
      "step": 8600
    },
    {
      "epoch": 37.46971736204576,
      "grad_norm": 1.4641993045806885,
      "learning_rate": 0.0001356127007241621,
      "loss": 0.8722,
      "num_input_tokens_seen": 17711032,
      "step": 8700
    },
    {
      "epoch": 37.90040376850606,
      "grad_norm": 1.9433013200759888,
      "learning_rate": 0.0001348399724926484,
      "loss": 0.8842,
      "num_input_tokens_seen": 17913656,
      "step": 8800
    },
    {
      "epoch": 38.331090174966356,
      "grad_norm": 2.036252975463867,
      "learning_rate": 0.0001340803046307982,
      "loss": 0.82,
      "num_input_tokens_seen": 18118576,
      "step": 8900
    },
    {
      "epoch": 38.76177658142665,
      "grad_norm": 1.8991620540618896,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.8552,
      "num_input_tokens_seen": 18321744,
      "step": 9000
    },
    {
      "epoch": 38.76177658142665,
      "eval_BLEU": 12.881524814130875,
      "eval_chrF": 65.61430116792269,
      "eval_loss": 0.7650089263916016,
      "eval_runtime": 5308.0652,
      "eval_samples_per_second": 5.599,
      "eval_steps_per_second": 1.4,
      "num_input_tokens_seen": 18321744,
      "step": 9000
    },
    {
      "epoch": 39.19246298788695,
      "grad_norm": 2.2481019496917725,
      "learning_rate": 0.00013259870882635917,
      "loss": 0.8809,
      "num_input_tokens_seen": 18525512,
      "step": 9100
    },
    {
      "epoch": 39.623149394347244,
      "grad_norm": 2.0596673488616943,
      "learning_rate": 0.00013187609467915743,
      "loss": 0.8385,
      "num_input_tokens_seen": 18728776,
      "step": 9200
    },
    {
      "epoch": 40.05383580080753,
      "grad_norm": 1.789355754852295,
      "learning_rate": 0.0001311651671567906,
      "loss": 0.8509,
      "num_input_tokens_seen": 18932288,
      "step": 9300
    },
    {
      "epoch": 40.48452220726783,
      "grad_norm": 1.6563084125518799,
      "learning_rate": 0.00013046561461068845,
      "loss": 0.8073,
      "num_input_tokens_seen": 19135904,
      "step": 9400
    },
    {
      "epoch": 40.915208613728126,
      "grad_norm": 1.796708106994629,
      "learning_rate": 0.00012977713690461005,
      "loss": 0.8512,
      "num_input_tokens_seen": 19338176,
      "step": 9500
    },
    {
      "epoch": 41.34589502018842,
      "grad_norm": 2.0318901538848877,
      "learning_rate": 0.00012909944487358058,
      "loss": 0.7672,
      "num_input_tokens_seen": 19543160,
      "step": 9600
    },
    {
      "epoch": 41.77658142664872,
      "grad_norm": 2.321376323699951,
      "learning_rate": 0.00012843225981358714,
      "loss": 0.8274,
      "num_input_tokens_seen": 19747032,
      "step": 9700
    },
    {
      "epoch": 42.207267833109015,
      "grad_norm": 2.7181572914123535,
      "learning_rate": 0.000127775312999988,
      "loss": 0.8642,
      "num_input_tokens_seen": 19948816,
      "step": 9800
    },
    {
      "epoch": 42.63795423956931,
      "grad_norm": 3.09661602973938,
      "learning_rate": 0.00012712834523274564,
      "loss": 0.7949,
      "num_input_tokens_seen": 20152048,
      "step": 9900
    },
    {
      "epoch": 43.06864064602961,
      "grad_norm": 1.721734642982483,
      "learning_rate": 0.00012649110640673518,
      "loss": 0.7967,
      "num_input_tokens_seen": 20357480,
      "step": 10000
    },
    {
      "epoch": 43.06864064602961,
      "eval_BLEU": 25.335365346090022,
      "eval_chrF": 70.97311221453941,
      "eval_loss": 0.6976158618927002,
      "eval_runtime": 4058.6807,
      "eval_samples_per_second": 7.322,
      "eval_steps_per_second": 1.831,
      "num_input_tokens_seen": 20357480,
      "step": 10000
    },
    {
      "epoch": 43.4993270524899,
      "grad_norm": 1.9550131559371948,
      "learning_rate": 0.00012586335510551052,
      "loss": 0.771,
      "num_input_tokens_seen": 20560744,
      "step": 10100
    },
    {
      "epoch": 43.9300134589502,
      "grad_norm": 1.4711147546768188,
      "learning_rate": 0.0001252448582170299,
      "loss": 0.7971,
      "num_input_tokens_seen": 20763208,
      "step": 10200
    },
    {
      "epoch": 44.360699865410496,
      "grad_norm": 1.7460564374923706,
      "learning_rate": 0.00012463539056995117,
      "loss": 0.7342,
      "num_input_tokens_seen": 20967744,
      "step": 10300
    },
    {
      "epoch": 44.79138627187079,
      "grad_norm": 2.0181753635406494,
      "learning_rate": 0.00012403473458920844,
      "loss": 0.7835,
      "num_input_tokens_seen": 21171296,
      "step": 10400
    },
    {
      "epoch": 45.22207267833109,
      "grad_norm": 1.5345689058303833,
      "learning_rate": 0.00012344267996967353,
      "loss": 0.8319,
      "num_input_tokens_seen": 21373976,
      "step": 10500
    },
    {
      "epoch": 45.652759084791384,
      "grad_norm": 1.2398273944854736,
      "learning_rate": 0.00012285902336679026,
      "loss": 0.7513,
      "num_input_tokens_seen": 21577624,
      "step": 10600
    },
    {
      "epoch": 46.08344549125168,
      "grad_norm": 1.6855307817459106,
      "learning_rate": 0.00012228356810314864,
      "loss": 0.7381,
      "num_input_tokens_seen": 21782128,
      "step": 10700
    },
    {
      "epoch": 46.51413189771198,
      "grad_norm": 1.6900908946990967,
      "learning_rate": 0.0001217161238900369,
      "loss": 0.74,
      "num_input_tokens_seen": 21986000,
      "step": 10800
    },
    {
      "epoch": 46.94481830417227,
      "grad_norm": 2.891101837158203,
      "learning_rate": 0.00012115650656307654,
      "loss": 0.7576,
      "num_input_tokens_seen": 22187984,
      "step": 10900
    },
    {
      "epoch": 47.37550471063257,
      "grad_norm": 2.4231576919555664,
      "learning_rate": 0.00012060453783110546,
      "loss": 0.7074,
      "num_input_tokens_seen": 22392936,
      "step": 11000
    },
    {
      "epoch": 47.37550471063257,
      "eval_BLEU": 30.6398072295773,
      "eval_chrF": 73.06028054092688,
      "eval_loss": 0.6380701661109924,
      "eval_runtime": 3920.2454,
      "eval_samples_per_second": 7.581,
      "eval_steps_per_second": 1.895,
      "num_input_tokens_seen": 22392936,
      "step": 11000
    },
    {
      "epoch": 47.806191117092865,
      "grad_norm": 2.9203901290893555,
      "learning_rate": 0.00012006004503753285,
      "loss": 0.7487,
      "num_input_tokens_seen": 22596104,
      "step": 11100
    },
    {
      "epoch": 48.23687752355316,
      "grad_norm": 1.2113069295883179,
      "learning_rate": 0.00011952286093343937,
      "loss": 0.7776,
      "num_input_tokens_seen": 22800000,
      "step": 11200
    },
    {
      "epoch": 48.66756393001346,
      "grad_norm": 1.7675807476043701,
      "learning_rate": 0.00011899282346174592,
      "loss": 0.7241,
      "num_input_tokens_seen": 23003040,
      "step": 11300
    },
    {
      "epoch": 49.098250336473754,
      "grad_norm": 1.3789281845092773,
      "learning_rate": 0.00011846977555181847,
      "loss": 0.6926,
      "num_input_tokens_seen": 23206520,
      "step": 11400
    },
    {
      "epoch": 49.52893674293405,
      "grad_norm": 2.728402614593506,
      "learning_rate": 0.00011795356492391772,
      "loss": 0.7069,
      "num_input_tokens_seen": 23409912,
      "step": 11500
    },
    {
      "epoch": 49.959623149394346,
      "grad_norm": 2.028895139694214,
      "learning_rate": 0.0001174440439029407,
      "loss": 0.7383,
      "num_input_tokens_seen": 23612536,
      "step": 11600
    },
    {
      "epoch": 50.39030955585464,
      "grad_norm": 2.3092520236968994,
      "learning_rate": 0.00011694106924093723,
      "loss": 0.6871,
      "num_input_tokens_seen": 23818096,
      "step": 11700
    },
    {
      "epoch": 50.82099596231494,
      "grad_norm": 2.581726551055908,
      "learning_rate": 0.0001164445019479164,
      "loss": 0.7107,
      "num_input_tokens_seen": 24021328,
      "step": 11800
    },
    {
      "epoch": 51.251682368775235,
      "grad_norm": 1.566662073135376,
      "learning_rate": 0.0001159542071304897,
      "loss": 0.7312,
      "num_input_tokens_seen": 24224488,
      "step": 11900
    },
    {
      "epoch": 51.68236877523553,
      "grad_norm": 1.681511402130127,
      "learning_rate": 0.00011547005383792517,
      "loss": 0.6899,
      "num_input_tokens_seen": 24428008,
      "step": 12000
    },
    {
      "epoch": 51.68236877523553,
      "eval_BLEU": 50.797297077157204,
      "eval_chrF": 76.56202287209807,
      "eval_loss": 0.5994001030921936,
      "eval_runtime": 2160.1577,
      "eval_samples_per_second": 13.758,
      "eval_steps_per_second": 3.44,
      "num_input_tokens_seen": 24428008,
      "step": 12000
    },
    {
      "epoch": 52.11305518169583,
      "grad_norm": 2.1072254180908203,
      "learning_rate": 0.00011499191491521382,
      "loss": 0.6639,
      "num_input_tokens_seen": 24631744,
      "step": 12100
    },
    {
      "epoch": 52.543741588156124,
      "grad_norm": 1.825735330581665,
      "learning_rate": 0.00011451966686277364,
      "loss": 0.6877,
      "num_input_tokens_seen": 24835392,
      "step": 12200
    },
    {
      "epoch": 52.97442799461642,
      "grad_norm": 2.5447723865509033,
      "learning_rate": 0.00011405318970244021,
      "loss": 0.7196,
      "num_input_tokens_seen": 25037472,
      "step": 12300
    },
    {
      "epoch": 53.405114401076716,
      "grad_norm": 2.2674036026000977,
      "learning_rate": 0.00011359236684941297,
      "loss": 0.6643,
      "num_input_tokens_seen": 25242360,
      "step": 12400
    },
    {
      "epoch": 53.83580080753701,
      "grad_norm": 2.8102164268493652,
      "learning_rate": 0.00011313708498984761,
      "loss": 0.6706,
      "num_input_tokens_seen": 25446136,
      "step": 12500
    },
    {
      "epoch": 54.26648721399731,
      "grad_norm": 1.9402508735656738,
      "learning_rate": 0.0001126872339638022,
      "loss": 0.693,
      "num_input_tokens_seen": 25648944,
      "step": 12600
    },
    {
      "epoch": 54.697173620457605,
      "grad_norm": 2.0698304176330566,
      "learning_rate": 0.00011224270665326275,
      "loss": 0.6618,
      "num_input_tokens_seen": 25852656,
      "step": 12700
    },
    {
      "epoch": 55.1278600269179,
      "grad_norm": 1.7410495281219482,
      "learning_rate": 0.0001118033988749895,
      "loss": 0.6307,
      "num_input_tokens_seen": 26056680,
      "step": 12800
    },
    {
      "epoch": 55.5585464333782,
      "grad_norm": 2.430104970932007,
      "learning_rate": 0.00011136920927794092,
      "loss": 0.6513,
      "num_input_tokens_seen": 26260296,
      "step": 12900
    },
    {
      "epoch": 55.98923283983849,
      "grad_norm": 2.373399019241333,
      "learning_rate": 0.00011094003924504583,
      "loss": 0.7137,
      "num_input_tokens_seen": 26462472,
      "step": 13000
    },
    {
      "epoch": 55.98923283983849,
      "eval_BLEU": 50.41471800894491,
      "eval_chrF": 77.33888792856165,
      "eval_loss": 0.5547034740447998,
      "eval_runtime": 2283.0326,
      "eval_samples_per_second": 13.017,
      "eval_steps_per_second": 3.254,
      "num_input_tokens_seen": 26462472,
      "step": 13000
    },
    {
      "epoch": 56.41991924629879,
      "grad_norm": 3.2287402153015137,
      "learning_rate": 0.00011051579279910753,
      "loss": 0.6308,
      "num_input_tokens_seen": 26666464,
      "step": 13100
    },
    {
      "epoch": 56.850605652759086,
      "grad_norm": 3.3205058574676514,
      "learning_rate": 0.00011009637651263606,
      "loss": 0.6726,
      "num_input_tokens_seen": 26869664,
      "step": 13200
    },
    {
      "epoch": 57.28129205921938,
      "grad_norm": 1.7785649299621582,
      "learning_rate": 0.00010968169942141635,
      "loss": 0.6255,
      "num_input_tokens_seen": 27074104,
      "step": 13300
    },
    {
      "epoch": 57.71197846567968,
      "grad_norm": 1.7982834577560425,
      "learning_rate": 0.0001092716729416306,
      "loss": 0.6462,
      "num_input_tokens_seen": 27277304,
      "step": 13400
    },
    {
      "epoch": 58.142664872139974,
      "grad_norm": 2.0695810317993164,
      "learning_rate": 0.00010886621079036347,
      "loss": 0.6178,
      "num_input_tokens_seen": 27480976,
      "step": 13500
    },
    {
      "epoch": 58.57335127860027,
      "grad_norm": 1.9080177545547485,
      "learning_rate": 0.00010846522890932808,
      "loss": 0.6275,
      "num_input_tokens_seen": 27684048,
      "step": 13600
    },
    {
      "epoch": 59.00403768506057,
      "grad_norm": 1.6623188257217407,
      "learning_rate": 0.00010806864539165984,
      "loss": 0.707,
      "num_input_tokens_seen": 27886504,
      "step": 13700
    },
    {
      "epoch": 59.43472409152086,
      "grad_norm": 1.559431791305542,
      "learning_rate": 0.0001076763804116331,
      "loss": 0.6133,
      "num_input_tokens_seen": 28090088,
      "step": 13800
    },
    {
      "epoch": 59.86541049798116,
      "grad_norm": 1.7218066453933716,
      "learning_rate": 0.00010728835615716402,
      "loss": 0.6309,
      "num_input_tokens_seen": 28293256,
      "step": 13900
    },
    {
      "epoch": 60.296096904441455,
      "grad_norm": 2.713700294494629,
      "learning_rate": 0.00010690449676496977,
      "loss": 0.5975,
      "num_input_tokens_seen": 28498656,
      "step": 14000
    },
    {
      "epoch": 60.296096904441455,
      "eval_BLEU": 63.25294425090161,
      "eval_chrF": 79.30330672874118,
      "eval_loss": 0.5168054103851318,
      "eval_runtime": 2004.774,
      "eval_samples_per_second": 14.824,
      "eval_steps_per_second": 3.706,
      "num_input_tokens_seen": 28498656,
      "step": 14000
    },
    {
      "epoch": 60.72678331090175,
      "grad_norm": 1.7807828187942505,
      "learning_rate": 0.0001065247282582615,
      "loss": 0.6225,
      "num_input_tokens_seen": 28702112,
      "step": 14100
    },
    {
      "epoch": 61.15746971736205,
      "grad_norm": 1.9338946342468262,
      "learning_rate": 0.00010614897848685506,
      "loss": 0.5794,
      "num_input_tokens_seen": 28905848,
      "step": 14200
    },
    {
      "epoch": 61.588156123822344,
      "grad_norm": 2.3524410724639893,
      "learning_rate": 0.00010577717706958901,
      "loss": 0.6123,
      "num_input_tokens_seen": 29109304,
      "step": 14300
    },
    {
      "epoch": 62.01884253028264,
      "grad_norm": 1.1010820865631104,
      "learning_rate": 0.00010540925533894598,
      "loss": 0.6765,
      "num_input_tokens_seen": 29312784,
      "step": 14400
    },
    {
      "epoch": 62.44952893674294,
      "grad_norm": 1.5284168720245361,
      "learning_rate": 0.00010504514628777804,
      "loss": 0.6039,
      "num_input_tokens_seen": 29516144,
      "step": 14500
    },
    {
      "epoch": 62.88021534320323,
      "grad_norm": 1.4796085357666016,
      "learning_rate": 0.00010468478451804274,
      "loss": 0.6062,
      "num_input_tokens_seen": 29718480,
      "step": 14600
    },
    {
      "epoch": 63.31090174966353,
      "grad_norm": 2.023346185684204,
      "learning_rate": 0.00010432810619146023,
      "loss": 0.5732,
      "num_input_tokens_seen": 29923176,
      "step": 14700
    },
    {
      "epoch": 63.741588156123825,
      "grad_norm": 1.840063214302063,
      "learning_rate": 0.00010397504898200727,
      "loss": 0.6043,
      "num_input_tokens_seen": 30126568,
      "step": 14800
    },
    {
      "epoch": 64.17227456258412,
      "grad_norm": 2.464087724685669,
      "learning_rate": 0.00010362555203016795,
      "loss": 0.5863,
      "num_input_tokens_seen": 30330816,
      "step": 14900
    },
    {
      "epoch": 64.60296096904442,
      "grad_norm": 2.789992094039917,
      "learning_rate": 0.00010327955589886444,
      "loss": 0.5924,
      "num_input_tokens_seen": 30534208,
      "step": 15000
    },
    {
      "epoch": 64.60296096904442,
      "eval_BLEU": 49.66565320819983,
      "eval_chrF": 79.14618653408917,
      "eval_loss": 0.48798251152038574,
      "eval_runtime": 2268.8213,
      "eval_samples_per_second": 13.099,
      "eval_steps_per_second": 3.275,
      "num_input_tokens_seen": 30534208,
      "step": 15000
    },
    {
      "epoch": 65.03364737550471,
      "grad_norm": 1.6696416139602661,
      "learning_rate": 0.00010293700253099577,
      "loss": 0.6286,
      "num_input_tokens_seen": 30737688,
      "step": 15100
    },
    {
      "epoch": 65.46433378196501,
      "grad_norm": 1.531753659248352,
      "learning_rate": 0.00010259783520851542,
      "loss": 0.5744,
      "num_input_tokens_seen": 30941208,
      "step": 15200
    },
    {
      "epoch": 65.8950201884253,
      "grad_norm": 1.921770691871643,
      "learning_rate": 0.00010226199851298272,
      "loss": 0.5977,
      "num_input_tokens_seen": 31143512,
      "step": 15300
    },
    {
      "epoch": 66.3257065948856,
      "grad_norm": 1.5567518472671509,
      "learning_rate": 0.00010192943828752511,
      "loss": 0.5421,
      "num_input_tokens_seen": 31348112,
      "step": 15400
    },
    {
      "epoch": 66.7563930013459,
      "grad_norm": 1.8409467935562134,
      "learning_rate": 0.00010160010160015241,
      "loss": 0.5701,
      "num_input_tokens_seen": 31552112,
      "step": 15500
    },
    {
      "epoch": 67.1870794078062,
      "grad_norm": 2.776550054550171,
      "learning_rate": 0.00010127393670836667,
      "loss": 0.6092,
      "num_input_tokens_seen": 31755656,
      "step": 15600
    },
    {
      "epoch": 67.61776581426649,
      "grad_norm": 2.2765040397644043,
      "learning_rate": 0.00010095089302501375,
      "loss": 0.5732,
      "num_input_tokens_seen": 31959528,
      "step": 15700
    },
    {
      "epoch": 68.04845222072679,
      "grad_norm": 1.7563849687576294,
      "learning_rate": 0.00010063092108532553,
      "loss": 0.5762,
      "num_input_tokens_seen": 32162432,
      "step": 15800
    },
    {
      "epoch": 68.47913862718708,
      "grad_norm": 1.834962248802185,
      "learning_rate": 0.00010031397251510383,
      "loss": 0.5464,
      "num_input_tokens_seen": 32365664,
      "step": 15900
    },
    {
      "epoch": 68.90982503364738,
      "grad_norm": 1.5346757173538208,
      "learning_rate": 0.0001,
      "loss": 0.595,
      "num_input_tokens_seen": 32568384,
      "step": 16000
    },
    {
      "epoch": 68.90982503364738,
      "eval_BLEU": 54.5179568361245,
      "eval_chrF": 79.99992155848041,
      "eval_loss": 0.4622350335121155,
      "eval_runtime": 2235.8476,
      "eval_samples_per_second": 13.292,
      "eval_steps_per_second": 3.323,
      "num_input_tokens_seen": 32568384,
      "step": 16000
    },
    {
      "epoch": 69.34051144010768,
      "grad_norm": 1.9430309534072876,
      "learning_rate": 9.968895725584536e-05,
      "loss": 0.5199,
      "num_input_tokens_seen": 32772920,
      "step": 16100
    },
    {
      "epoch": 69.77119784656797,
      "grad_norm": 2.115729808807373,
      "learning_rate": 9.938079899999067e-05,
      "loss": 0.5673,
      "num_input_tokens_seen": 32976248,
      "step": 16200
    },
    {
      "epoch": 70.20188425302827,
      "grad_norm": 2.8067033290863037,
      "learning_rate": 9.9075480923614e-05,
      "loss": 0.5886,
      "num_input_tokens_seen": 33180208,
      "step": 16300
    },
    {
      "epoch": 70.63257065948856,
      "grad_norm": 3.5109469890594482,
      "learning_rate": 9.877295966495897e-05,
      "loss": 0.5521,
      "num_input_tokens_seen": 33383856,
      "step": 16400
    },
    {
      "epoch": 71.06325706594886,
      "grad_norm": 1.7607839107513428,
      "learning_rate": 9.847319278346618e-05,
      "loss": 0.5639,
      "num_input_tokens_seen": 33587080,
      "step": 16500
    },
    {
      "epoch": 71.49394347240916,
      "grad_norm": 1.871153473854065,
      "learning_rate": 9.81761387347632e-05,
      "loss": 0.5454,
      "num_input_tokens_seen": 33790472,
      "step": 16600
    },
    {
      "epoch": 71.92462987886945,
      "grad_norm": 1.7990353107452393,
      "learning_rate": 9.788175684647928e-05,
      "loss": 0.556,
      "num_input_tokens_seen": 33993000,
      "step": 16700
    },
    {
      "epoch": 72.35531628532975,
      "grad_norm": 2.087336778640747,
      "learning_rate": 9.759000729485331e-05,
      "loss": 0.509,
      "num_input_tokens_seen": 34197504,
      "step": 16800
    },
    {
      "epoch": 72.78600269179005,
      "grad_norm": 1.9567492008209229,
      "learning_rate": 9.730085108210398e-05,
      "loss": 0.5457,
      "num_input_tokens_seen": 34401056,
      "step": 16900
    },
    {
      "epoch": 73.21668909825034,
      "grad_norm": 2.629559278488159,
      "learning_rate": 9.70142500145332e-05,
      "loss": 0.5995,
      "num_input_tokens_seen": 34603000,
      "step": 17000
    },
    {
      "epoch": 73.21668909825034,
      "eval_BLEU": 65.65969138163035,
      "eval_chrF": 81.08549517782136,
      "eval_loss": 0.43571653962135315,
      "eval_runtime": 2192.6868,
      "eval_samples_per_second": 13.554,
      "eval_steps_per_second": 3.389,
      "num_input_tokens_seen": 34603000,
      "step": 17000
    },
    {
      "epoch": 73.64737550471064,
      "grad_norm": 2.824648141860962,
      "learning_rate": 9.673016668133489e-05,
      "loss": 0.5426,
      "num_input_tokens_seen": 34806456,
      "step": 17100
    },
    {
      "epoch": 74.07806191117093,
      "grad_norm": 1.7349662780761719,
      "learning_rate": 9.644856443408244e-05,
      "loss": 0.5093,
      "num_input_tokens_seen": 35011728,
      "step": 17200
    },
    {
      "epoch": 74.50874831763123,
      "grad_norm": 1.8855921030044556,
      "learning_rate": 9.616940736686902e-05,
      "loss": 0.5377,
      "num_input_tokens_seen": 35215184,
      "step": 17300
    },
    {
      "epoch": 74.93943472409153,
      "grad_norm": 1.7380480766296387,
      "learning_rate": 9.589266029707684e-05,
      "loss": 0.5364,
      "num_input_tokens_seen": 35417616,
      "step": 17400
    },
    {
      "epoch": 75.37012113055182,
      "grad_norm": 1.909057378768921,
      "learning_rate": 9.561828874675149e-05,
      "loss": 0.5022,
      "num_input_tokens_seen": 35622632,
      "step": 17500
    },
    {
      "epoch": 75.80080753701212,
      "grad_norm": 1.7569183111190796,
      "learning_rate": 9.534625892455923e-05,
      "loss": 0.5376,
      "num_input_tokens_seen": 35826056,
      "step": 17600
    },
    {
      "epoch": 76.23149394347242,
      "grad_norm": 1.6262644529342651,
      "learning_rate": 9.507653770830567e-05,
      "loss": 0.5755,
      "num_input_tokens_seen": 36028800,
      "step": 17700
    },
    {
      "epoch": 76.66218034993271,
      "grad_norm": 1.2700988054275513,
      "learning_rate": 9.480909262799545e-05,
      "loss": 0.5175,
      "num_input_tokens_seen": 36232992,
      "step": 17800
    },
    {
      "epoch": 77.09286675639301,
      "grad_norm": 1.6186245679855347,
      "learning_rate": 9.45438918494131e-05,
      "loss": 0.4983,
      "num_input_tokens_seen": 36436376,
      "step": 17900
    },
    {
      "epoch": 77.5235531628533,
      "grad_norm": 2.2780649662017822,
      "learning_rate": 9.428090415820635e-05,
      "loss": 0.5108,
      "num_input_tokens_seen": 36640184,
      "step": 18000
    },
    {
      "epoch": 77.5235531628533,
      "eval_BLEU": 61.567305669135,
      "eval_chrF": 82.00210433026105,
      "eval_loss": 0.4160268008708954,
      "eval_runtime": 2133.4064,
      "eval_samples_per_second": 13.93,
      "eval_steps_per_second": 3.483,
      "num_input_tokens_seen": 36640184,
      "step": 18000
    },
    {
      "epoch": 77.9542395693136,
      "grad_norm": 2.2136240005493164,
      "learning_rate": 9.402009894445369e-05,
      "loss": 0.5374,
      "num_input_tokens_seen": 36842552,
      "step": 18100
    },
    {
      "epoch": 78.3849259757739,
      "grad_norm": 2.281521797180176,
      "learning_rate": 9.376144618769909e-05,
      "loss": 0.4981,
      "num_input_tokens_seen": 37047376,
      "step": 18200
    },
    {
      "epoch": 78.81561238223419,
      "grad_norm": 2.6163454055786133,
      "learning_rate": 9.350491644243689e-05,
      "loss": 0.5205,
      "num_input_tokens_seen": 37250864,
      "step": 18300
    },
    {
      "epoch": 79.24629878869449,
      "grad_norm": 1.9647883176803589,
      "learning_rate": 9.325048082403138e-05,
      "loss": 0.5316,
      "num_input_tokens_seen": 37454184,
      "step": 18400
    },
    {
      "epoch": 79.67698519515478,
      "grad_norm": 1.1027621030807495,
      "learning_rate": 9.299811099505544e-05,
      "loss": 0.5146,
      "num_input_tokens_seen": 37657704,
      "step": 18500
    },
    {
      "epoch": 80.10767160161507,
      "grad_norm": 1.6940577030181885,
      "learning_rate": 9.274777915203365e-05,
      "loss": 0.4904,
      "num_input_tokens_seen": 37861696,
      "step": 18600
    },
    {
      "epoch": 80.53835800807536,
      "grad_norm": 1.6934322118759155,
      "learning_rate": 9.249945801257606e-05,
      "loss": 0.5018,
      "num_input_tokens_seen": 38064992,
      "step": 18700
    },
    {
      "epoch": 80.96904441453566,
      "grad_norm": 2.722580671310425,
      "learning_rate": 9.225312080288851e-05,
      "loss": 0.5384,
      "num_input_tokens_seen": 38267200,
      "step": 18800
    },
    {
      "epoch": 81.39973082099596,
      "grad_norm": 2.0058953762054443,
      "learning_rate": 9.200874124564724e-05,
      "loss": 0.4853,
      "num_input_tokens_seen": 38472056,
      "step": 18900
    },
    {
      "epoch": 81.83041722745625,
      "grad_norm": 2.4916975498199463,
      "learning_rate": 9.17662935482247e-05,
      "loss": 0.5049,
      "num_input_tokens_seen": 38675384,
      "step": 19000
    },
    {
      "epoch": 81.83041722745625,
      "eval_BLEU": 65.69281013867682,
      "eval_chrF": 82.35030758460009,
      "eval_loss": 0.4006138741970062,
      "eval_runtime": 2070.5925,
      "eval_samples_per_second": 14.353,
      "eval_steps_per_second": 3.588,
      "num_input_tokens_seen": 38675384,
      "step": 19000
    },
    {
      "epoch": 82.26110363391655,
      "grad_norm": 1.0221666097640991,
      "learning_rate": 9.152575239125511e-05,
      "loss": 0.51,
      "num_input_tokens_seen": 38878832,
      "step": 19100
    },
    {
      "epoch": 82.69179004037684,
      "grad_norm": 1.540431022644043,
      "learning_rate": 9.12870929175277e-05,
      "loss": 0.4951,
      "num_input_tokens_seen": 39082512,
      "step": 19200
    },
    {
      "epoch": 83.12247644683714,
      "grad_norm": 1.740073800086975,
      "learning_rate": 9.105029072119708e-05,
      "loss": 0.4766,
      "num_input_tokens_seen": 39286120,
      "step": 19300
    },
    {
      "epoch": 83.55316285329744,
      "grad_norm": 2.106849431991577,
      "learning_rate": 9.081532183729996e-05,
      "loss": 0.4837,
      "num_input_tokens_seen": 39489736,
      "step": 19400
    },
    {
      "epoch": 83.98384925975773,
      "grad_norm": 2.549722194671631,
      "learning_rate": 9.058216273156765e-05,
      "loss": 0.5436,
      "num_input_tokens_seen": 39692264,
      "step": 19500
    },
    {
      "epoch": 84.41453566621803,
      "grad_norm": 2.636462450027466,
      "learning_rate": 9.035079029052513e-05,
      "loss": 0.4769,
      "num_input_tokens_seen": 39896960,
      "step": 19600
    },
    {
      "epoch": 84.84522207267833,
      "grad_norm": 2.2726802825927734,
      "learning_rate": 9.012118181186659e-05,
      "loss": 0.4909,
      "num_input_tokens_seen": 40100320,
      "step": 19700
    },
    {
      "epoch": 85.27590847913862,
      "grad_norm": 1.606468677520752,
      "learning_rate": 8.989331499509895e-05,
      "loss": 0.4841,
      "num_input_tokens_seen": 40303960,
      "step": 19800
    },
    {
      "epoch": 85.70659488559892,
      "grad_norm": 1.8425705432891846,
      "learning_rate": 8.966716793244407e-05,
      "loss": 0.4959,
      "num_input_tokens_seen": 40507352,
      "step": 19900
    },
    {
      "epoch": 86.13728129205921,
      "grad_norm": 1.8025538921356201,
      "learning_rate": 8.944271909999159e-05,
      "loss": 0.4587,
      "num_input_tokens_seen": 40710896,
      "step": 20000
    },
    {
      "epoch": 86.13728129205921,
      "eval_BLEU": 56.276180334717786,
      "eval_chrF": 82.02876202413756,
      "eval_loss": 0.38155046105384827,
      "eval_runtime": 2272.5343,
      "eval_samples_per_second": 13.077,
      "eval_steps_per_second": 3.269,
      "num_input_tokens_seen": 40710896,
      "step": 20000
    },
    {
      "epoch": 86.56796769851951,
      "grad_norm": 1.9768295288085938,
      "learning_rate": 8.92199473490941e-05,
      "loss": 0.4703,
      "num_input_tokens_seen": 40913968,
      "step": 20100
    },
    {
      "epoch": 86.9986541049798,
      "grad_norm": 3.498262882232666,
      "learning_rate": 8.899883189799696e-05,
      "loss": 0.5521,
      "num_input_tokens_seen": 41114992,
      "step": 20200
    },
    {
      "epoch": 87.4293405114401,
      "grad_norm": 3.4689013957977295,
      "learning_rate": 8.877935232369506e-05,
      "loss": 0.4741,
      "num_input_tokens_seen": 41318344,
      "step": 20300
    },
    {
      "epoch": 87.8600269179004,
      "grad_norm": 3.3331806659698486,
      "learning_rate": 8.856148855400954e-05,
      "loss": 0.4772,
      "num_input_tokens_seen": 41522024,
      "step": 20400
    },
    {
      "epoch": 88.2907133243607,
      "grad_norm": 1.6614729166030884,
      "learning_rate": 8.834522085987723e-05,
      "loss": 0.4507,
      "num_input_tokens_seen": 41728128,
      "step": 20500
    },
    {
      "epoch": 88.72139973082099,
      "grad_norm": 1.579344630241394,
      "learning_rate": 8.813052984784634e-05,
      "loss": 0.4758,
      "num_input_tokens_seen": 41931904,
      "step": 20600
    },
    {
      "epoch": 89.15208613728129,
      "grad_norm": 1.6740541458129883,
      "learning_rate": 8.79173964527716e-05,
      "loss": 0.4427,
      "num_input_tokens_seen": 42135864,
      "step": 20700
    },
    {
      "epoch": 89.58277254374158,
      "grad_norm": 1.8959999084472656,
      "learning_rate": 8.770580193070293e-05,
      "loss": 0.4695,
      "num_input_tokens_seen": 42339352,
      "step": 20800
    },
    {
      "epoch": 90.01345895020188,
      "grad_norm": 1.2468554973602295,
      "learning_rate": 8.749572785196143e-05,
      "loss": 0.5227,
      "num_input_tokens_seen": 42542576,
      "step": 20900
    },
    {
      "epoch": 90.44414535666218,
      "grad_norm": 1.112606406211853,
      "learning_rate": 8.728715609439696e-05,
      "loss": 0.4571,
      "num_input_tokens_seen": 42746416,
      "step": 21000
    },
    {
      "epoch": 90.44414535666218,
      "eval_BLEU": 54.77882236514854,
      "eval_chrF": 82.9207783613559,
      "eval_loss": 0.36803755164146423,
      "eval_runtime": 2186.2959,
      "eval_samples_per_second": 13.593,
      "eval_steps_per_second": 3.398,
      "num_input_tokens_seen": 42746416,
      "step": 21000
    },
    {
      "epoch": 90.87483176312247,
      "grad_norm": 1.0120937824249268,
      "learning_rate": 8.708006883682163e-05,
      "loss": 0.4647,
      "num_input_tokens_seen": 42948496,
      "step": 21100
    },
    {
      "epoch": 91.30551816958277,
      "grad_norm": 1.4512841701507568,
      "learning_rate": 8.687444855261388e-05,
      "loss": 0.4393,
      "num_input_tokens_seen": 43153192,
      "step": 21200
    },
    {
      "epoch": 91.73620457604306,
      "grad_norm": 1.6085726022720337,
      "learning_rate": 8.66702780034879e-05,
      "loss": 0.4615,
      "num_input_tokens_seen": 43356968,
      "step": 21300
    },
    {
      "epoch": 92.16689098250336,
      "grad_norm": 1.8595941066741943,
      "learning_rate": 8.64675402334234e-05,
      "loss": 0.4613,
      "num_input_tokens_seen": 43560864,
      "step": 21400
    },
    {
      "epoch": 92.59757738896366,
      "grad_norm": 2.384181261062622,
      "learning_rate": 8.626621856275073e-05,
      "loss": 0.4572,
      "num_input_tokens_seen": 43764512,
      "step": 21500
    },
    {
      "epoch": 93.02826379542395,
      "grad_norm": 1.1763354539871216,
      "learning_rate": 8.606629658238704e-05,
      "loss": 0.4939,
      "num_input_tokens_seen": 43967512,
      "step": 21600
    },
    {
      "epoch": 93.45895020188425,
      "grad_norm": 1.0385923385620117,
      "learning_rate": 8.586775814821838e-05,
      "loss": 0.451,
      "num_input_tokens_seen": 44170296,
      "step": 21700
    },
    {
      "epoch": 93.88963660834455,
      "grad_norm": 1.1547906398773193,
      "learning_rate": 8.567058737562387e-05,
      "loss": 0.4602,
      "num_input_tokens_seen": 44373240,
      "step": 21800
    },
    {
      "epoch": 94.32032301480484,
      "grad_norm": 1.4242490530014038,
      "learning_rate": 8.547476863413766e-05,
      "loss": 0.4225,
      "num_input_tokens_seen": 44577968,
      "step": 21900
    },
    {
      "epoch": 94.75100942126514,
      "grad_norm": 1.4682625532150269,
      "learning_rate": 8.528028654224417e-05,
      "loss": 0.4536,
      "num_input_tokens_seen": 44781648,
      "step": 22000
    },
    {
      "epoch": 94.75100942126514,
      "eval_BLEU": 50.333189964681935,
      "eval_chrF": 81.41931074697133,
      "eval_loss": 0.3560463786125183,
      "eval_runtime": 2361.8547,
      "eval_samples_per_second": 12.583,
      "eval_steps_per_second": 3.146,
      "num_input_tokens_seen": 44781648,
      "step": 22000
    },
    {
      "epoch": 95.18169582772543,
      "grad_norm": 2.363119602203369,
      "learning_rate": 8.508712596230342e-05,
      "loss": 0.4576,
      "num_input_tokens_seen": 44985576,
      "step": 22100
    },
    {
      "epoch": 95.61238223418573,
      "grad_norm": 2.3328793048858643,
      "learning_rate": 8.489527199560179e-05,
      "loss": 0.4444,
      "num_input_tokens_seen": 45189320,
      "step": 22200
    },
    {
      "epoch": 96.04306864064603,
      "grad_norm": 1.1048810482025146,
      "learning_rate": 8.470470997752536e-05,
      "loss": 0.4759,
      "num_input_tokens_seen": 45392032,
      "step": 22300
    },
    {
      "epoch": 96.47375504710632,
      "grad_norm": 1.0940275192260742,
      "learning_rate": 8.451542547285167e-05,
      "loss": 0.4424,
      "num_input_tokens_seen": 45595296,
      "step": 22400
    },
    {
      "epoch": 96.90444145356662,
      "grad_norm": 1.6287851333618164,
      "learning_rate": 8.432740427115679e-05,
      "loss": 0.4619,
      "num_input_tokens_seen": 45798240,
      "step": 22500
    },
    {
      "epoch": 97.33512786002692,
      "grad_norm": 2.047499179840088,
      "learning_rate": 8.414063238233425e-05,
      "loss": 0.4068,
      "num_input_tokens_seen": 46003288,
      "step": 22600
    },
    {
      "epoch": 97.76581426648721,
      "grad_norm": 2.043626070022583,
      "learning_rate": 8.39550960322227e-05,
      "loss": 0.4531,
      "num_input_tokens_seen": 46206488,
      "step": 22700
    },
    {
      "epoch": 98.19650067294751,
      "grad_norm": 2.572732448577881,
      "learning_rate": 8.377078165833911e-05,
      "loss": 0.4625,
      "num_input_tokens_seen": 46410224,
      "step": 22800
    },
    {
      "epoch": 98.6271870794078,
      "grad_norm": 2.2029287815093994,
      "learning_rate": 8.358767590571457e-05,
      "loss": 0.4402,
      "num_input_tokens_seen": 46613456,
      "step": 22900
    },
    {
      "epoch": 99.0578734858681,
      "grad_norm": 1.6221120357513428,
      "learning_rate": 8.340576562282991e-05,
      "loss": 0.4441,
      "num_input_tokens_seen": 46817256,
      "step": 23000
    },
    {
      "epoch": 99.0578734858681,
      "eval_BLEU": 58.80725717959854,
      "eval_chrF": 83.20180496900946,
      "eval_loss": 0.34311071038246155,
      "eval_runtime": 2078.1864,
      "eval_samples_per_second": 14.3,
      "eval_steps_per_second": 3.575,
      "num_input_tokens_seen": 46817256,
      "step": 23000
    },
    {
      "epoch": 99.4885598923284,
      "grad_norm": 1.885512351989746,
      "learning_rate": 8.32250378576479e-05,
      "loss": 0.4379,
      "num_input_tokens_seen": 47020296,
      "step": 23100
    },
    {
      "epoch": 99.91924629878869,
      "grad_norm": 1.888089656829834,
      "learning_rate": 8.304547985373997e-05,
      "loss": 0.4397,
      "num_input_tokens_seen": 47223208,
      "step": 23200
    },
    {
      "epoch": 100.34993270524899,
      "grad_norm": 2.1853363513946533,
      "learning_rate": 8.286707904650417e-05,
      "loss": 0.3982,
      "num_input_tokens_seen": 47427840,
      "step": 23300
    },
    {
      "epoch": 100.78061911170929,
      "grad_norm": 1.7094142436981201,
      "learning_rate": 8.268982305947231e-05,
      "loss": 0.4463,
      "num_input_tokens_seen": 47631552,
      "step": 23400
    },
    {
      "epoch": 101.21130551816958,
      "grad_norm": 2.998699903488159,
      "learning_rate": 8.251369970070348e-05,
      "loss": 0.4827,
      "num_input_tokens_seen": 47832440,
      "step": 23500
    },
    {
      "epoch": 101.64199192462988,
      "grad_norm": 3.5082075595855713,
      "learning_rate": 8.233869695926183e-05,
      "loss": 0.4237,
      "num_input_tokens_seen": 48036344,
      "step": 23600
    },
    {
      "epoch": 102.07267833109017,
      "grad_norm": 1.4009134769439697,
      "learning_rate": 8.216480300177611e-05,
      "loss": 0.4264,
      "num_input_tokens_seen": 48241904,
      "step": 23700
    },
    {
      "epoch": 102.50336473755047,
      "grad_norm": 1.750948190689087,
      "learning_rate": 8.199200616907878e-05,
      "loss": 0.4111,
      "num_input_tokens_seen": 48445456,
      "step": 23800
    },
    {
      "epoch": 102.93405114401077,
      "grad_norm": 1.672721266746521,
      "learning_rate": 8.182029497292263e-05,
      "loss": 0.4356,
      "num_input_tokens_seen": 48648080,
      "step": 23900
    },
    {
      "epoch": 103.36473755047106,
      "grad_norm": 1.8639681339263916,
      "learning_rate": 8.164965809277262e-05,
      "loss": 0.4102,
      "num_input_tokens_seen": 48852936,
      "step": 24000
    },
    {
      "epoch": 103.36473755047106,
      "eval_BLEU": 59.44831173175577,
      "eval_chrF": 83.60959036240827,
      "eval_loss": 0.32975730299949646,
      "eval_runtime": 2806.2822,
      "eval_samples_per_second": 10.59,
      "eval_steps_per_second": 2.648,
      "num_input_tokens_seen": 48852936,
      "step": 24000
    },
    {
      "epoch": 103.79542395693136,
      "grad_norm": 2.063825845718384,
      "learning_rate": 8.148008437267105e-05,
      "loss": 0.4275,
      "num_input_tokens_seen": 49056392,
      "step": 24100
    },
    {
      "epoch": 104.22611036339165,
      "grad_norm": 1.2221853733062744,
      "learning_rate": 8.131156281817418e-05,
      "loss": 0.4711,
      "num_input_tokens_seen": 49259424,
      "step": 24200
    },
    {
      "epoch": 104.65679676985195,
      "grad_norm": 0.9806608557701111,
      "learning_rate": 8.114408259335794e-05,
      "loss": 0.4288,
      "num_input_tokens_seen": 49463072,
      "step": 24300
    },
    {
      "epoch": 105.08748317631225,
      "grad_norm": 1.5497422218322754,
      "learning_rate": 8.097763301789161e-05,
      "loss": 0.3896,
      "num_input_tokens_seen": 49666840,
      "step": 24400
    },
    {
      "epoch": 105.51816958277254,
      "grad_norm": 1.45143461227417,
      "learning_rate": 8.081220356417685e-05,
      "loss": 0.4237,
      "num_input_tokens_seen": 49870712,
      "step": 24500
    },
    {
      "epoch": 105.94885598923284,
      "grad_norm": 1.7689985036849976,
      "learning_rate": 8.064778385455119e-05,
      "loss": 0.4206,
      "num_input_tokens_seen": 50072952,
      "step": 24600
    },
    {
      "epoch": 106.37954239569314,
      "grad_norm": 2.6059722900390625,
      "learning_rate": 8.048436365855337e-05,
      "loss": 0.3932,
      "num_input_tokens_seen": 50278032,
      "step": 24700
    },
    {
      "epoch": 106.81022880215343,
      "grad_norm": 2.4588894844055176,
      "learning_rate": 8.032193289024989e-05,
      "loss": 0.4252,
      "num_input_tokens_seen": 50481232,
      "step": 24800
    },
    {
      "epoch": 107.24091520861373,
      "grad_norm": 0.9359570741653442,
      "learning_rate": 8.016048160562024e-05,
      "loss": 0.4532,
      "num_input_tokens_seen": 50685096,
      "step": 24900
    },
    {
      "epoch": 107.67160161507402,
      "grad_norm": 1.0483043193817139,
      "learning_rate": 8e-05,
      "loss": 0.4171,
      "num_input_tokens_seen": 50888008,
      "step": 25000
    },
    {
      "epoch": 107.67160161507402,
      "eval_BLEU": 64.49732058108445,
      "eval_chrF": 83.98129809557427,
      "eval_loss": 0.3193749487400055,
      "eval_runtime": 2723.767,
      "eval_samples_per_second": 10.911,
      "eval_steps_per_second": 2.728,
      "num_input_tokens_seen": 50888008,
      "step": 25000
    },
    {
      "epoch": 108.10228802153432,
      "grad_norm": 1.4358776807785034,
      "learning_rate": 7.984047840557992e-05,
      "loss": 0.3888,
      "num_input_tokens_seen": 51091936,
      "step": 25100
    },
    {
      "epoch": 108.53297442799462,
      "grad_norm": 1.5391385555267334,
      "learning_rate": 7.968190728895958e-05,
      "loss": 0.411,
      "num_input_tokens_seen": 51295616,
      "step": 25200
    },
    {
      "epoch": 108.96366083445491,
      "grad_norm": 2.2190465927124023,
      "learning_rate": 7.952427724875441e-05,
      "loss": 0.4334,
      "num_input_tokens_seen": 51497920,
      "step": 25300
    },
    {
      "epoch": 109.39434724091521,
      "grad_norm": 2.3665666580200195,
      "learning_rate": 7.936757901325451e-05,
      "loss": 0.3949,
      "num_input_tokens_seen": 51702520,
      "step": 25400
    },
    {
      "epoch": 109.8250336473755,
      "grad_norm": 2.036841630935669,
      "learning_rate": 7.921180343813396e-05,
      "loss": 0.4166,
      "num_input_tokens_seen": 51905752,
      "step": 25500
    },
    {
      "epoch": 110.2557200538358,
      "grad_norm": 1.185760259628296,
      "learning_rate": 7.905694150420948e-05,
      "loss": 0.4136,
      "num_input_tokens_seen": 52109808,
      "step": 25600
    },
    {
      "epoch": 110.6864064602961,
      "grad_norm": 1.018005609512329,
      "learning_rate": 7.890298431524716e-05,
      "loss": 0.4107,
      "num_input_tokens_seen": 52312784,
      "step": 25700
    },
    {
      "epoch": 111.1170928667564,
      "grad_norm": 1.808384895324707,
      "learning_rate": 7.874992309581578e-05,
      "loss": 0.3913,
      "num_input_tokens_seen": 52516872,
      "step": 25800
    },
    {
      "epoch": 111.54777927321669,
      "grad_norm": 1.932475209236145,
      "learning_rate": 7.859774918918594e-05,
      "loss": 0.3978,
      "num_input_tokens_seen": 52720616,
      "step": 25900
    },
    {
      "epoch": 111.97846567967699,
      "grad_norm": 2.302243232727051,
      "learning_rate": 7.844645405527362e-05,
      "loss": 0.4416,
      "num_input_tokens_seen": 52922792,
      "step": 26000
    },
    {
      "epoch": 111.97846567967699,
      "eval_BLEU": 57.38419781453928,
      "eval_chrF": 83.7801823144265,
      "eval_loss": 0.3125765919685364,
      "eval_runtime": 2878.2708,
      "eval_samples_per_second": 10.325,
      "eval_steps_per_second": 2.581,
      "num_input_tokens_seen": 52922792,
      "step": 26000
    },
    {
      "epoch": 112.40915208613728,
      "grad_norm": 2.397651433944702,
      "learning_rate": 7.829602926862714e-05,
      "loss": 0.3975,
      "num_input_tokens_seen": 53127744,
      "step": 26100
    },
    {
      "epoch": 112.83983849259758,
      "grad_norm": 2.695143699645996,
      "learning_rate": 7.814646651645635e-05,
      "loss": 0.3986,
      "num_input_tokens_seen": 53331008,
      "step": 26200
    },
    {
      "epoch": 113.27052489905788,
      "grad_norm": 1.467151403427124,
      "learning_rate": 7.799775759670319e-05,
      "loss": 0.4052,
      "num_input_tokens_seen": 53534424,
      "step": 26300
    },
    {
      "epoch": 113.70121130551817,
      "grad_norm": 1.451736330986023,
      "learning_rate": 7.78498944161523e-05,
      "loss": 0.404,
      "num_input_tokens_seen": 53737720,
      "step": 26400
    },
    {
      "epoch": 114.13189771197847,
      "grad_norm": 1.74747896194458,
      "learning_rate": 7.770286898858113e-05,
      "loss": 0.3821,
      "num_input_tokens_seen": 53941680,
      "step": 26500
    },
    {
      "epoch": 114.56258411843876,
      "grad_norm": 2.2080307006835938,
      "learning_rate": 7.755667343294812e-05,
      "loss": 0.4043,
      "num_input_tokens_seen": 54144784,
      "step": 26600
    },
    {
      "epoch": 114.99327052489906,
      "grad_norm": 3.145752429962158,
      "learning_rate": 7.741129997161835e-05,
      "loss": 0.4347,
      "num_input_tokens_seen": 54346896,
      "step": 26700
    },
    {
      "epoch": 115.42395693135936,
      "grad_norm": 3.6778323650360107,
      "learning_rate": 7.726674092862558e-05,
      "loss": 0.3893,
      "num_input_tokens_seen": 54550664,
      "step": 26800
    },
    {
      "epoch": 115.85464333781965,
      "grad_norm": 3.7227931022644043,
      "learning_rate": 7.71229887279699e-05,
      "loss": 0.399,
      "num_input_tokens_seen": 54754184,
      "step": 26900
    },
    {
      "epoch": 116.28532974427995,
      "grad_norm": 1.6326149702072144,
      "learning_rate": 7.698003589195011e-05,
      "loss": 0.3878,
      "num_input_tokens_seen": 54958816,
      "step": 27000
    },
    {
      "epoch": 116.28532974427995,
      "eval_BLEU": 62.94861468873513,
      "eval_chrF": 84.41863636601862,
      "eval_loss": 0.30466726422309875,
      "eval_runtime": 2778.3955,
      "eval_samples_per_second": 10.696,
      "eval_steps_per_second": 2.674,
      "num_input_tokens_seen": 54958816,
      "step": 27000
    },
    {
      "epoch": 116.71601615074024,
      "grad_norm": 1.7609902620315552,
      "learning_rate": 7.683787503952986e-05,
      "loss": 0.3959,
      "num_input_tokens_seen": 55162208,
      "step": 27100
    },
    {
      "epoch": 117.14670255720054,
      "grad_norm": 1.973240613937378,
      "learning_rate": 7.669649888473704e-05,
      "loss": 0.3694,
      "num_input_tokens_seen": 55366648,
      "step": 27200
    },
    {
      "epoch": 117.57738896366084,
      "grad_norm": 1.797353982925415,
      "learning_rate": 7.655590023509528e-05,
      "loss": 0.3903,
      "num_input_tokens_seen": 55570008,
      "step": 27300
    },
    {
      "epoch": 118.00807537012113,
      "grad_norm": 1.1869033575057983,
      "learning_rate": 7.641607199008701e-05,
      "loss": 0.4448,
      "num_input_tokens_seen": 55772880,
      "step": 27400
    },
    {
      "epoch": 118.43876177658143,
      "grad_norm": 1.055694818496704,
      "learning_rate": 7.62770071396474e-05,
      "loss": 0.3792,
      "num_input_tokens_seen": 55976560,
      "step": 27500
    },
    {
      "epoch": 118.86944818304173,
      "grad_norm": 1.4844541549682617,
      "learning_rate": 7.61386987626881e-05,
      "loss": 0.3994,
      "num_input_tokens_seen": 56179056,
      "step": 27600
    },
    {
      "epoch": 119.30013458950202,
      "grad_norm": 1.507137417793274,
      "learning_rate": 7.600114002565064e-05,
      "loss": 0.3577,
      "num_input_tokens_seen": 56383720,
      "step": 27700
    },
    {
      "epoch": 119.73082099596232,
      "grad_norm": 1.609693169593811,
      "learning_rate": 7.586432418108816e-05,
      "loss": 0.3889,
      "num_input_tokens_seen": 56587048,
      "step": 27800
    },
    {
      "epoch": 120.16150740242261,
      "grad_norm": 2.1253883838653564,
      "learning_rate": 7.57282445662753e-05,
      "loss": 0.3727,
      "num_input_tokens_seen": 56791360,
      "step": 27900
    },
    {
      "epoch": 120.59219380888291,
      "grad_norm": 2.207988739013672,
      "learning_rate": 7.559289460184545e-05,
      "loss": 0.3817,
      "num_input_tokens_seen": 56994816,
      "step": 28000
    },
    {
      "epoch": 120.59219380888291,
      "eval_BLEU": 61.335999906660476,
      "eval_chrF": 83.98203579842536,
      "eval_loss": 0.29463937878608704,
      "eval_runtime": 2875.1026,
      "eval_samples_per_second": 10.337,
      "eval_steps_per_second": 2.584,
      "num_input_tokens_seen": 56994816,
      "step": 28000
    },
    {
      "epoch": 121.0228802153432,
      "grad_norm": 0.8734928369522095,
      "learning_rate": 7.545826779045449e-05,
      "loss": 0.4302,
      "num_input_tokens_seen": 57197976,
      "step": 28100
    },
    {
      "epoch": 121.4535666218035,
      "grad_norm": 1.1713515520095825,
      "learning_rate": 7.532435771547095e-05,
      "loss": 0.3725,
      "num_input_tokens_seen": 57401464,
      "step": 28200
    },
    {
      "epoch": 121.8842530282638,
      "grad_norm": 1.1262173652648926,
      "learning_rate": 7.519115803969124e-05,
      "loss": 0.3845,
      "num_input_tokens_seen": 57604248,
      "step": 28300
    },
    {
      "epoch": 122.3149394347241,
      "grad_norm": 1.5020856857299805,
      "learning_rate": 7.505866250408016e-05,
      "loss": 0.3635,
      "num_input_tokens_seen": 57809040,
      "step": 28400
    },
    {
      "epoch": 122.74562584118439,
      "grad_norm": 1.3297452926635742,
      "learning_rate": 7.492686492653552e-05,
      "loss": 0.374,
      "num_input_tokens_seen": 58012848,
      "step": 28500
    },
    {
      "epoch": 123.17631224764469,
      "grad_norm": 3.206758737564087,
      "learning_rate": 7.479575920067657e-05,
      "loss": 0.3972,
      "num_input_tokens_seen": 58216424,
      "step": 28600
    },
    {
      "epoch": 123.60699865410498,
      "grad_norm": 2.2558090686798096,
      "learning_rate": 7.466533929465574e-05,
      "loss": 0.3706,
      "num_input_tokens_seen": 58419944,
      "step": 28700
    },
    {
      "epoch": 124.03768506056528,
      "grad_norm": 1.2205909490585327,
      "learning_rate": 7.453559924999299e-05,
      "loss": 0.4087,
      "num_input_tokens_seen": 58623008,
      "step": 28800
    },
    {
      "epoch": 124.46837146702558,
      "grad_norm": 1.0194858312606812,
      "learning_rate": 7.440653318043245e-05,
      "loss": 0.3763,
      "num_input_tokens_seen": 58826624,
      "step": 28900
    },
    {
      "epoch": 124.89905787348587,
      "grad_norm": 1.5519527196884155,
      "learning_rate": 7.427813527082075e-05,
      "loss": 0.3759,
      "num_input_tokens_seen": 59029248,
      "step": 29000
    },
    {
      "epoch": 124.89905787348587,
      "eval_BLEU": 67.73754020879127,
      "eval_chrF": 84.64194726803255,
      "eval_loss": 0.2887182831764221,
      "eval_runtime": 2887.4253,
      "eval_samples_per_second": 10.293,
      "eval_steps_per_second": 2.573,
      "num_input_tokens_seen": 59029248,
      "step": 29000
    },
    {
      "epoch": 125.32974427994617,
      "grad_norm": 1.604862093925476,
      "learning_rate": 7.415039977600647e-05,
      "loss": 0.3519,
      "num_input_tokens_seen": 59234040,
      "step": 29100
    },
    {
      "epoch": 125.76043068640647,
      "grad_norm": 2.075683355331421,
      "learning_rate": 7.402332101976053e-05,
      "loss": 0.381,
      "num_input_tokens_seen": 59437144,
      "step": 29200
    },
    {
      "epoch": 126.19111709286676,
      "grad_norm": 2.2138524055480957,
      "learning_rate": 7.389689339371664e-05,
      "loss": 0.389,
      "num_input_tokens_seen": 59640752,
      "step": 29300
    },
    {
      "epoch": 126.62180349932706,
      "grad_norm": 2.45658016204834,
      "learning_rate": 7.377111135633174e-05,
      "loss": 0.3752,
      "num_input_tokens_seen": 59844336,
      "step": 29400
    },
    {
      "epoch": 127.05248990578735,
      "grad_norm": 1.368026852607727,
      "learning_rate": 7.364596943186588e-05,
      "loss": 0.3795,
      "num_input_tokens_seen": 60047976,
      "step": 29500
    },
    {
      "epoch": 127.48317631224765,
      "grad_norm": 1.246258020401001,
      "learning_rate": 7.352146220938078e-05,
      "loss": 0.3689,
      "num_input_tokens_seen": 60251880,
      "step": 29600
    },
    {
      "epoch": 127.91386271870795,
      "grad_norm": 1.1504902839660645,
      "learning_rate": 7.339758434175737e-05,
      "loss": 0.3845,
      "num_input_tokens_seen": 60453768,
      "step": 29700
    },
    {
      "epoch": 128.34454912516824,
      "grad_norm": 1.6883256435394287,
      "learning_rate": 7.327433054473117e-05,
      "loss": 0.338,
      "num_input_tokens_seen": 60658720,
      "step": 29800
    },
    {
      "epoch": 128.77523553162854,
      "grad_norm": 2.1414308547973633,
      "learning_rate": 7.315169559594551e-05,
      "loss": 0.3762,
      "num_input_tokens_seen": 60862208,
      "step": 29900
    },
    {
      "epoch": 129.20592193808884,
      "grad_norm": 3.6782848834991455,
      "learning_rate": 7.302967433402214e-05,
      "loss": 0.3975,
      "num_input_tokens_seen": 61064472,
      "step": 30000
    },
    {
      "epoch": 129.20592193808884,
      "eval_BLEU": 66.55616060304718,
      "eval_chrF": 84.70548873396123,
      "eval_loss": 0.28056955337524414,
      "eval_runtime": 2774.1325,
      "eval_samples_per_second": 10.713,
      "eval_steps_per_second": 2.678,
      "num_input_tokens_seen": 61064472,
      "step": 30000
    }
  ],
  "logging_steps": 100,
  "max_steps": 1000000,
  "num_input_tokens_seen": 61064472,
  "num_train_epochs": 4311,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.179591454010245e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
