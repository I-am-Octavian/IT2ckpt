{
  "best_metric": 65.69281013867682,
  "best_model_checkpoint": "output/checkpoint-19000",
  "epoch": 81.83041722745625,
  "eval_steps": 1000,
  "global_step": 19000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.4306864064602961,
      "grad_norm": 1.701179027557373,
      "learning_rate": 5e-06,
      "loss": 5.125,
      "num_input_tokens_seen": 203872,
      "step": 100
    },
    {
      "epoch": 0.8613728129205922,
      "grad_norm": 2.3627851009368896,
      "learning_rate": 1e-05,
      "loss": 4.6606,
      "num_input_tokens_seen": 406976,
      "step": 200
    },
    {
      "epoch": 1.2920592193808882,
      "grad_norm": 0.576862633228302,
      "learning_rate": 1.5e-05,
      "loss": 3.4913,
      "num_input_tokens_seen": 613656,
      "step": 300
    },
    {
      "epoch": 1.7227456258411844,
      "grad_norm": 0.4405195415019989,
      "learning_rate": 2e-05,
      "loss": 2.9889,
      "num_input_tokens_seen": 816792,
      "step": 400
    },
    {
      "epoch": 2.1534320323014806,
      "grad_norm": 0.37419113516807556,
      "learning_rate": 2.5e-05,
      "loss": 2.6069,
      "num_input_tokens_seen": 1020976,
      "step": 500
    },
    {
      "epoch": 2.5841184387617764,
      "grad_norm": 0.4175524413585663,
      "learning_rate": 3e-05,
      "loss": 2.4343,
      "num_input_tokens_seen": 1224432,
      "step": 600
    },
    {
      "epoch": 3.0148048452220726,
      "grad_norm": 0.3354434669017792,
      "learning_rate": 3.5e-05,
      "loss": 2.3478,
      "num_input_tokens_seen": 1427688,
      "step": 700
    },
    {
      "epoch": 3.445491251682369,
      "grad_norm": 0.39046090841293335,
      "learning_rate": 4e-05,
      "loss": 2.2189,
      "num_input_tokens_seen": 1631112,
      "step": 800
    },
    {
      "epoch": 3.876177658142665,
      "grad_norm": 0.39334172010421753,
      "learning_rate": 4.5e-05,
      "loss": 2.1035,
      "num_input_tokens_seen": 1833736,
      "step": 900
    },
    {
      "epoch": 4.306864064602961,
      "grad_norm": 0.5705759525299072,
      "learning_rate": 5e-05,
      "loss": 2.0168,
      "num_input_tokens_seen": 2038912,
      "step": 1000
    },
    {
      "epoch": 4.306864064602961,
      "eval_BLEU": 3.8122341012643473,
      "eval_chrF": 36.43280946301253,
      "eval_loss": 2.019329071044922,
      "eval_runtime": 9134.4198,
      "eval_samples_per_second": 3.254,
      "eval_steps_per_second": 0.813,
      "num_input_tokens_seen": 2038912,
      "step": 1000
    },
    {
      "epoch": 4.737550471063257,
      "grad_norm": 0.5001136660575867,
      "learning_rate": 5.500000000000001e-05,
      "loss": 2.0445,
      "num_input_tokens_seen": 2241920,
      "step": 1100
    },
    {
      "epoch": 5.168236877523553,
      "grad_norm": 0.7218773365020752,
      "learning_rate": 6e-05,
      "loss": 1.9738,
      "num_input_tokens_seen": 2445976,
      "step": 1200
    },
    {
      "epoch": 5.598923283983849,
      "grad_norm": 0.6985712051391602,
      "learning_rate": 6.500000000000001e-05,
      "loss": 1.9574,
      "num_input_tokens_seen": 2649688,
      "step": 1300
    },
    {
      "epoch": 6.029609690444145,
      "grad_norm": 0.5494056940078735,
      "learning_rate": 7e-05,
      "loss": 1.9731,
      "num_input_tokens_seen": 2852656,
      "step": 1400
    },
    {
      "epoch": 6.460296096904441,
      "grad_norm": 0.5963790416717529,
      "learning_rate": 7.500000000000001e-05,
      "loss": 1.8964,
      "num_input_tokens_seen": 3056272,
      "step": 1500
    },
    {
      "epoch": 6.890982503364738,
      "grad_norm": 0.659528911113739,
      "learning_rate": 8e-05,
      "loss": 1.8906,
      "num_input_tokens_seen": 3258416,
      "step": 1600
    },
    {
      "epoch": 7.321668909825034,
      "grad_norm": 0.7196580171585083,
      "learning_rate": 8.5e-05,
      "loss": 1.7727,
      "num_input_tokens_seen": 3463272,
      "step": 1700
    },
    {
      "epoch": 7.75235531628533,
      "grad_norm": 0.7764711976051331,
      "learning_rate": 9e-05,
      "loss": 1.8272,
      "num_input_tokens_seen": 3666856,
      "step": 1800
    },
    {
      "epoch": 8.183041722745626,
      "grad_norm": 0.9047828316688538,
      "learning_rate": 9.5e-05,
      "loss": 1.8578,
      "num_input_tokens_seen": 3870528,
      "step": 1900
    },
    {
      "epoch": 8.613728129205922,
      "grad_norm": 0.9182494282722473,
      "learning_rate": 0.0001,
      "loss": 1.7839,
      "num_input_tokens_seen": 4073920,
      "step": 2000
    },
    {
      "epoch": 8.613728129205922,
      "eval_BLEU": 6.140892462109956,
      "eval_chrF": 42.39972027507838,
      "eval_loss": 1.7336806058883667,
      "eval_runtime": 6924.5283,
      "eval_samples_per_second": 4.292,
      "eval_steps_per_second": 1.073,
      "num_input_tokens_seen": 4073920,
      "step": 2000
    },
    {
      "epoch": 9.044414535666219,
      "grad_norm": 0.8307850956916809,
      "learning_rate": 0.000105,
      "loss": 1.7742,
      "num_input_tokens_seen": 4277016,
      "step": 2100
    },
    {
      "epoch": 9.475100942126515,
      "grad_norm": 0.8229411244392395,
      "learning_rate": 0.00011000000000000002,
      "loss": 1.7292,
      "num_input_tokens_seen": 4480888,
      "step": 2200
    },
    {
      "epoch": 9.90578734858681,
      "grad_norm": 1.0547361373901367,
      "learning_rate": 0.00011499999999999999,
      "loss": 1.7464,
      "num_input_tokens_seen": 4683384,
      "step": 2300
    },
    {
      "epoch": 10.336473755047106,
      "grad_norm": 0.9621979594230652,
      "learning_rate": 0.00012,
      "loss": 1.6566,
      "num_input_tokens_seen": 4888432,
      "step": 2400
    },
    {
      "epoch": 10.767160161507402,
      "grad_norm": 1.1656601428985596,
      "learning_rate": 0.000125,
      "loss": 1.6892,
      "num_input_tokens_seen": 5091984,
      "step": 2500
    },
    {
      "epoch": 11.197846567967698,
      "grad_norm": 1.2228089570999146,
      "learning_rate": 0.00013000000000000002,
      "loss": 1.7134,
      "num_input_tokens_seen": 5295496,
      "step": 2600
    },
    {
      "epoch": 11.628532974427994,
      "grad_norm": 1.32364821434021,
      "learning_rate": 0.00013500000000000003,
      "loss": 1.6609,
      "num_input_tokens_seen": 5499240,
      "step": 2700
    },
    {
      "epoch": 12.05921938088829,
      "grad_norm": 1.2049146890640259,
      "learning_rate": 0.00014,
      "loss": 1.6332,
      "num_input_tokens_seen": 5702432,
      "step": 2800
    },
    {
      "epoch": 12.489905787348587,
      "grad_norm": 1.0890871286392212,
      "learning_rate": 0.000145,
      "loss": 1.5769,
      "num_input_tokens_seen": 5905856,
      "step": 2900
    },
    {
      "epoch": 12.920592193808883,
      "grad_norm": 1.2266361713409424,
      "learning_rate": 0.00015000000000000001,
      "loss": 1.6332,
      "num_input_tokens_seen": 6108288,
      "step": 3000
    },
    {
      "epoch": 12.920592193808883,
      "eval_BLEU": 15.973661356987577,
      "eval_chrF": 52.84067681575597,
      "eval_loss": 1.5450592041015625,
      "eval_runtime": 3043.8758,
      "eval_samples_per_second": 9.764,
      "eval_steps_per_second": 2.441,
      "num_input_tokens_seen": 6108288,
      "step": 3000
    },
    {
      "epoch": 13.351278600269179,
      "grad_norm": 1.2481393814086914,
      "learning_rate": 0.000155,
      "loss": 1.5339,
      "num_input_tokens_seen": 6312952,
      "step": 3100
    },
    {
      "epoch": 13.781965006729475,
      "grad_norm": 1.2295877933502197,
      "learning_rate": 0.00016,
      "loss": 1.576,
      "num_input_tokens_seen": 6516664,
      "step": 3200
    },
    {
      "epoch": 14.212651413189771,
      "grad_norm": 1.7779520750045776,
      "learning_rate": 0.000165,
      "loss": 1.6042,
      "num_input_tokens_seen": 6717456,
      "step": 3300
    },
    {
      "epoch": 14.643337819650068,
      "grad_norm": 2.058474063873291,
      "learning_rate": 0.00017,
      "loss": 1.5447,
      "num_input_tokens_seen": 6921104,
      "step": 3400
    },
    {
      "epoch": 15.074024226110364,
      "grad_norm": 1.130005121231079,
      "learning_rate": 0.000175,
      "loss": 1.5009,
      "num_input_tokens_seen": 7127208,
      "step": 3500
    },
    {
      "epoch": 15.50471063257066,
      "grad_norm": 1.3730303049087524,
      "learning_rate": 0.00018,
      "loss": 1.4704,
      "num_input_tokens_seen": 7330536,
      "step": 3600
    },
    {
      "epoch": 15.935397039030956,
      "grad_norm": 1.302757740020752,
      "learning_rate": 0.00018500000000000002,
      "loss": 1.505,
      "num_input_tokens_seen": 7533128,
      "step": 3700
    },
    {
      "epoch": 16.366083445491252,
      "grad_norm": 1.5146578550338745,
      "learning_rate": 0.00019,
      "loss": 1.4405,
      "num_input_tokens_seen": 7738080,
      "step": 3800
    },
    {
      "epoch": 16.79676985195155,
      "grad_norm": 1.5347174406051636,
      "learning_rate": 0.000195,
      "loss": 1.479,
      "num_input_tokens_seen": 7941728,
      "step": 3900
    },
    {
      "epoch": 17.227456258411845,
      "grad_norm": 1.137338638305664,
      "learning_rate": 0.0002,
      "loss": 1.5005,
      "num_input_tokens_seen": 8144952,
      "step": 4000
    },
    {
      "epoch": 17.227456258411845,
      "eval_BLEU": 12.800747168424515,
      "eval_chrF": 53.59983240106829,
      "eval_loss": 1.3618903160095215,
      "eval_runtime": 3497.7432,
      "eval_samples_per_second": 8.497,
      "eval_steps_per_second": 2.124,
      "num_input_tokens_seen": 8144952,
      "step": 4000
    },
    {
      "epoch": 17.65814266487214,
      "grad_norm": 1.1301511526107788,
      "learning_rate": 0.00019754591932991794,
      "loss": 1.4222,
      "num_input_tokens_seen": 8347864,
      "step": 4100
    },
    {
      "epoch": 18.088829071332437,
      "grad_norm": 1.3690111637115479,
      "learning_rate": 0.00019518001458970662,
      "loss": 1.3794,
      "num_input_tokens_seen": 8552176,
      "step": 4200
    },
    {
      "epoch": 18.519515477792734,
      "grad_norm": 1.3094570636749268,
      "learning_rate": 0.00019289712886816487,
      "loss": 1.3799,
      "num_input_tokens_seen": 8755376,
      "step": 4300
    },
    {
      "epoch": 18.95020188425303,
      "grad_norm": 1.403018832206726,
      "learning_rate": 0.00019069251784911847,
      "loss": 1.4015,
      "num_input_tokens_seen": 8958000,
      "step": 4400
    },
    {
      "epoch": 19.380888290713326,
      "grad_norm": 2.004037380218506,
      "learning_rate": 0.0001885618083164127,
      "loss": 1.3189,
      "num_input_tokens_seen": 9163080,
      "step": 4500
    },
    {
      "epoch": 19.81157469717362,
      "grad_norm": 1.7128154039382935,
      "learning_rate": 0.00018650096164806276,
      "loss": 1.3595,
      "num_input_tokens_seen": 9366504,
      "step": 4600
    },
    {
      "epoch": 20.242261103633915,
      "grad_norm": 1.3525723218917847,
      "learning_rate": 0.00018450624160577702,
      "loss": 1.3538,
      "num_input_tokens_seen": 9570144,
      "step": 4700
    },
    {
      "epoch": 20.67294751009421,
      "grad_norm": 1.2210636138916016,
      "learning_rate": 0.0001825741858350554,
      "loss": 1.3156,
      "num_input_tokens_seen": 9773376,
      "step": 4800
    },
    {
      "epoch": 21.103633916554507,
      "grad_norm": 1.6344140768051147,
      "learning_rate": 0.00018070158058105027,
      "loss": 1.2594,
      "num_input_tokens_seen": 9976952,
      "step": 4900
    },
    {
      "epoch": 21.534320323014803,
      "grad_norm": 1.5825331211090088,
      "learning_rate": 0.00017888543819998318,
      "loss": 1.2537,
      "num_input_tokens_seen": 10180920,
      "step": 5000
    },
    {
      "epoch": 21.534320323014803,
      "eval_BLEU": 17.32552941711246,
      "eval_chrF": 57.53860686246347,
      "eval_loss": 1.1931277513504028,
      "eval_runtime": 2955.5788,
      "eval_samples_per_second": 10.055,
      "eval_steps_per_second": 2.514,
      "num_input_tokens_seen": 10180920,
      "step": 5000
    },
    {
      "epoch": 21.9650067294751,
      "grad_norm": 1.791204810142517,
      "learning_rate": 0.00017712297710801908,
      "loss": 1.3061,
      "num_input_tokens_seen": 10382968,
      "step": 5100
    },
    {
      "epoch": 22.395693135935396,
      "grad_norm": 1.7956479787826538,
      "learning_rate": 0.00017541160386140586,
      "loss": 1.2253,
      "num_input_tokens_seen": 10587920,
      "step": 5200
    },
    {
      "epoch": 22.826379542395692,
      "grad_norm": 1.87252938747406,
      "learning_rate": 0.00017374889710522777,
      "loss": 1.2342,
      "num_input_tokens_seen": 10791280,
      "step": 5300
    },
    {
      "epoch": 23.25706594885599,
      "grad_norm": 1.4286614656448364,
      "learning_rate": 0.00017213259316477408,
      "loss": 1.2304,
      "num_input_tokens_seen": 10994600,
      "step": 5400
    },
    {
      "epoch": 23.687752355316285,
      "grad_norm": 1.5421695709228516,
      "learning_rate": 0.00017056057308448833,
      "loss": 1.2004,
      "num_input_tokens_seen": 11197832,
      "step": 5500
    },
    {
      "epoch": 24.11843876177658,
      "grad_norm": 1.8411788940429688,
      "learning_rate": 0.00016903085094570333,
      "loss": 1.1713,
      "num_input_tokens_seen": 11401728,
      "step": 5600
    },
    {
      "epoch": 24.549125168236877,
      "grad_norm": 1.714586615562439,
      "learning_rate": 0.00016754156331667822,
      "loss": 1.1707,
      "num_input_tokens_seen": 11604832,
      "step": 5700
    },
    {
      "epoch": 24.979811574697173,
      "grad_norm": 1.7752598524093628,
      "learning_rate": 0.00016609095970747994,
      "loss": 1.2133,
      "num_input_tokens_seen": 11807648,
      "step": 5800
    },
    {
      "epoch": 25.41049798115747,
      "grad_norm": 1.9991991519927979,
      "learning_rate": 0.00016467739391852365,
      "loss": 1.1125,
      "num_input_tokens_seen": 12012664,
      "step": 5900
    },
    {
      "epoch": 25.841184387617766,
      "grad_norm": 1.9995514154434204,
      "learning_rate": 0.00016329931618554524,
      "loss": 1.1556,
      "num_input_tokens_seen": 12216312,
      "step": 6000
    },
    {
      "epoch": 25.841184387617766,
      "eval_BLEU": 6.88972965925764,
      "eval_chrF": 50.624489459031,
      "eval_loss": 1.050746202468872,
      "eval_runtime": 7584.8544,
      "eval_samples_per_second": 3.918,
      "eval_steps_per_second": 0.98,
      "num_input_tokens_seen": 12216312,
      "step": 6000
    },
    {
      "epoch": 26.271870794078062,
      "grad_norm": 1.8837848901748657,
      "learning_rate": 0.00016195526603578322,
      "loss": 1.1266,
      "num_input_tokens_seen": 12419408,
      "step": 6100
    },
    {
      "epoch": 26.702557200538358,
      "grad_norm": 1.4847583770751953,
      "learning_rate": 0.00016064386578049978,
      "loss": 1.1063,
      "num_input_tokens_seen": 12622544,
      "step": 6200
    },
    {
      "epoch": 27.133243606998654,
      "grad_norm": 1.8079134225845337,
      "learning_rate": 0.00015936381457791915,
      "loss": 1.0669,
      "num_input_tokens_seen": 12826504,
      "step": 6300
    },
    {
      "epoch": 27.56393001345895,
      "grad_norm": 2.031217336654663,
      "learning_rate": 0.00015811388300841897,
      "loss": 1.0857,
      "num_input_tokens_seen": 13030120,
      "step": 6400
    },
    {
      "epoch": 27.994616419919247,
      "grad_norm": 2.965177297592163,
      "learning_rate": 0.00015689290811054724,
      "loss": 1.1571,
      "num_input_tokens_seen": 13231656,
      "step": 6500
    },
    {
      "epoch": 28.425302826379543,
      "grad_norm": 2.8897647857666016,
      "learning_rate": 0.0001556997888323046,
      "loss": 1.0559,
      "num_input_tokens_seen": 13435200,
      "step": 6600
    },
    {
      "epoch": 28.85598923283984,
      "grad_norm": 2.5745151042938232,
      "learning_rate": 0.00015453348185725117,
      "loss": 1.0635,
      "num_input_tokens_seen": 13638496,
      "step": 6700
    },
    {
      "epoch": 29.286675639300135,
      "grad_norm": 1.5488898754119873,
      "learning_rate": 0.00015339299776947408,
      "loss": 1.0178,
      "num_input_tokens_seen": 13844280,
      "step": 6800
    },
    {
      "epoch": 29.71736204576043,
      "grad_norm": 1.7955801486968994,
      "learning_rate": 0.0001522773975253762,
      "loss": 1.0415,
      "num_input_tokens_seen": 14047352,
      "step": 6900
    },
    {
      "epoch": 30.148048452220728,
      "grad_norm": 2.094613790512085,
      "learning_rate": 0.0001511857892036909,
      "loss": 0.9732,
      "num_input_tokens_seen": 14251248,
      "step": 7000
    },
    {
      "epoch": 30.148048452220728,
      "eval_BLEU": 33.338492109368794,
      "eval_chrF": 66.90934352332685,
      "eval_loss": 0.9279971122741699,
      "eval_runtime": 2279.3284,
      "eval_samples_per_second": 13.038,
      "eval_steps_per_second": 3.26,
      "num_input_tokens_seen": 14251248,
      "step": 7000
    },
    {
      "epoch": 30.578734858681024,
      "grad_norm": 1.865736722946167,
      "learning_rate": 0.00015011732500816032,
      "loss": 1.0102,
      "num_input_tokens_seen": 14454896,
      "step": 7100
    },
    {
      "epoch": 31.00942126514132,
      "grad_norm": 1.2109999656677246,
      "learning_rate": 0.00014907119849998598,
      "loss": 1.1009,
      "num_input_tokens_seen": 14657768,
      "step": 7200
    },
    {
      "epoch": 31.440107671601616,
      "grad_norm": 1.5130889415740967,
      "learning_rate": 0.00014804664203952106,
      "loss": 0.9732,
      "num_input_tokens_seen": 14861416,
      "step": 7300
    },
    {
      "epoch": 31.870794078061913,
      "grad_norm": 1.6439968347549438,
      "learning_rate": 0.00014704292441876157,
      "loss": 1.0091,
      "num_input_tokens_seen": 15064072,
      "step": 7400
    },
    {
      "epoch": 32.30148048452221,
      "grad_norm": 1.3424618244171143,
      "learning_rate": 0.00014605934866804428,
      "loss": 0.9194,
      "num_input_tokens_seen": 15269056,
      "step": 7500
    },
    {
      "epoch": 32.732166890982505,
      "grad_norm": 1.835135817527771,
      "learning_rate": 0.00014509525002200235,
      "loss": 0.9713,
      "num_input_tokens_seen": 15472544,
      "step": 7600
    },
    {
      "epoch": 33.1628532974428,
      "grad_norm": 2.223942279815674,
      "learning_rate": 0.00014414999403128943,
      "loss": 0.9364,
      "num_input_tokens_seen": 15676088,
      "step": 7700
    },
    {
      "epoch": 33.5935397039031,
      "grad_norm": 4.038457870483398,
      "learning_rate": 0.00014322297480788657,
      "loss": 0.9422,
      "num_input_tokens_seen": 15879608,
      "step": 7800
    },
    {
      "epoch": 34.024226110363394,
      "grad_norm": 1.5377708673477173,
      "learning_rate": 0.000142313613392964,
      "loss": 1.0167,
      "num_input_tokens_seen": 16082928,
      "step": 7900
    },
    {
      "epoch": 34.45491251682369,
      "grad_norm": 1.3731310367584229,
      "learning_rate": 0.0001414213562373095,
      "loss": 0.902,
      "num_input_tokens_seen": 16286736,
      "step": 8000
    },
    {
      "epoch": 34.45491251682369,
      "eval_BLEU": 39.14441766196189,
      "eval_chrF": 69.73574414555578,
      "eval_loss": 0.8359068632125854,
      "eval_runtime": 2293.9147,
      "eval_samples_per_second": 12.956,
      "eval_steps_per_second": 3.239,
      "num_input_tokens_seen": 16286736,
      "step": 8000
    },
    {
      "epoch": 34.885598923283986,
      "grad_norm": 1.6181068420410156,
      "learning_rate": 0.0001405456737852613,
      "loss": 0.9329,
      "num_input_tokens_seen": 16489040,
      "step": 8100
    },
    {
      "epoch": 35.31628532974428,
      "grad_norm": 1.777456283569336,
      "learning_rate": 0.00013968605915391566,
      "loss": 0.8827,
      "num_input_tokens_seen": 16693576,
      "step": 8200
    },
    {
      "epoch": 35.74697173620458,
      "grad_norm": 2.1017963886260986,
      "learning_rate": 0.00013884202690012468,
      "loss": 0.9009,
      "num_input_tokens_seen": 16896904,
      "step": 8300
    },
    {
      "epoch": 36.177658142664875,
      "grad_norm": 2.061311960220337,
      "learning_rate": 0.00013801311186847085,
      "loss": 0.9263,
      "num_input_tokens_seen": 17101152,
      "step": 8400
    },
    {
      "epoch": 36.60834454912517,
      "grad_norm": 2.4050357341766357,
      "learning_rate": 0.00013719886811400705,
      "loss": 0.9,
      "num_input_tokens_seen": 17304128,
      "step": 8500
    },
    {
      "epoch": 37.03903095558547,
      "grad_norm": 1.7090213298797607,
      "learning_rate": 0.0001363988678940947,
      "loss": 0.917,
      "num_input_tokens_seen": 17507544,
      "step": 8600
    },
    {
      "epoch": 37.46971736204576,
      "grad_norm": 1.4641993045806885,
      "learning_rate": 0.0001356127007241621,
      "loss": 0.8722,
      "num_input_tokens_seen": 17711032,
      "step": 8700
    },
    {
      "epoch": 37.90040376850606,
      "grad_norm": 1.9433013200759888,
      "learning_rate": 0.0001348399724926484,
      "loss": 0.8842,
      "num_input_tokens_seen": 17913656,
      "step": 8800
    },
    {
      "epoch": 38.331090174966356,
      "grad_norm": 2.036252975463867,
      "learning_rate": 0.0001340803046307982,
      "loss": 0.82,
      "num_input_tokens_seen": 18118576,
      "step": 8900
    },
    {
      "epoch": 38.76177658142665,
      "grad_norm": 1.8991620540618896,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.8552,
      "num_input_tokens_seen": 18321744,
      "step": 9000
    },
    {
      "epoch": 38.76177658142665,
      "eval_BLEU": 12.881524814130875,
      "eval_chrF": 65.61430116792269,
      "eval_loss": 0.7650089263916016,
      "eval_runtime": 5308.0652,
      "eval_samples_per_second": 5.599,
      "eval_steps_per_second": 1.4,
      "num_input_tokens_seen": 18321744,
      "step": 9000
    },
    {
      "epoch": 39.19246298788695,
      "grad_norm": 2.2481019496917725,
      "learning_rate": 0.00013259870882635917,
      "loss": 0.8809,
      "num_input_tokens_seen": 18525512,
      "step": 9100
    },
    {
      "epoch": 39.623149394347244,
      "grad_norm": 2.0596673488616943,
      "learning_rate": 0.00013187609467915743,
      "loss": 0.8385,
      "num_input_tokens_seen": 18728776,
      "step": 9200
    },
    {
      "epoch": 40.05383580080753,
      "grad_norm": 1.789355754852295,
      "learning_rate": 0.0001311651671567906,
      "loss": 0.8509,
      "num_input_tokens_seen": 18932288,
      "step": 9300
    },
    {
      "epoch": 40.48452220726783,
      "grad_norm": 1.6563084125518799,
      "learning_rate": 0.00013046561461068845,
      "loss": 0.8073,
      "num_input_tokens_seen": 19135904,
      "step": 9400
    },
    {
      "epoch": 40.915208613728126,
      "grad_norm": 1.796708106994629,
      "learning_rate": 0.00012977713690461005,
      "loss": 0.8512,
      "num_input_tokens_seen": 19338176,
      "step": 9500
    },
    {
      "epoch": 41.34589502018842,
      "grad_norm": 2.0318901538848877,
      "learning_rate": 0.00012909944487358058,
      "loss": 0.7672,
      "num_input_tokens_seen": 19543160,
      "step": 9600
    },
    {
      "epoch": 41.77658142664872,
      "grad_norm": 2.321376323699951,
      "learning_rate": 0.00012843225981358714,
      "loss": 0.8274,
      "num_input_tokens_seen": 19747032,
      "step": 9700
    },
    {
      "epoch": 42.207267833109015,
      "grad_norm": 2.7181572914123535,
      "learning_rate": 0.000127775312999988,
      "loss": 0.8642,
      "num_input_tokens_seen": 19948816,
      "step": 9800
    },
    {
      "epoch": 42.63795423956931,
      "grad_norm": 3.09661602973938,
      "learning_rate": 0.00012712834523274564,
      "loss": 0.7949,
      "num_input_tokens_seen": 20152048,
      "step": 9900
    },
    {
      "epoch": 43.06864064602961,
      "grad_norm": 1.721734642982483,
      "learning_rate": 0.00012649110640673518,
      "loss": 0.7967,
      "num_input_tokens_seen": 20357480,
      "step": 10000
    },
    {
      "epoch": 43.06864064602961,
      "eval_BLEU": 25.335365346090022,
      "eval_chrF": 70.97311221453941,
      "eval_loss": 0.6976158618927002,
      "eval_runtime": 4058.6807,
      "eval_samples_per_second": 7.322,
      "eval_steps_per_second": 1.831,
      "num_input_tokens_seen": 20357480,
      "step": 10000
    },
    {
      "epoch": 43.4993270524899,
      "grad_norm": 1.9550131559371948,
      "learning_rate": 0.00012586335510551052,
      "loss": 0.771,
      "num_input_tokens_seen": 20560744,
      "step": 10100
    },
    {
      "epoch": 43.9300134589502,
      "grad_norm": 1.4711147546768188,
      "learning_rate": 0.0001252448582170299,
      "loss": 0.7971,
      "num_input_tokens_seen": 20763208,
      "step": 10200
    },
    {
      "epoch": 44.360699865410496,
      "grad_norm": 1.7460564374923706,
      "learning_rate": 0.00012463539056995117,
      "loss": 0.7342,
      "num_input_tokens_seen": 20967744,
      "step": 10300
    },
    {
      "epoch": 44.79138627187079,
      "grad_norm": 2.0181753635406494,
      "learning_rate": 0.00012403473458920844,
      "loss": 0.7835,
      "num_input_tokens_seen": 21171296,
      "step": 10400
    },
    {
      "epoch": 45.22207267833109,
      "grad_norm": 1.5345689058303833,
      "learning_rate": 0.00012344267996967353,
      "loss": 0.8319,
      "num_input_tokens_seen": 21373976,
      "step": 10500
    },
    {
      "epoch": 45.652759084791384,
      "grad_norm": 1.2398273944854736,
      "learning_rate": 0.00012285902336679026,
      "loss": 0.7513,
      "num_input_tokens_seen": 21577624,
      "step": 10600
    },
    {
      "epoch": 46.08344549125168,
      "grad_norm": 1.6855307817459106,
      "learning_rate": 0.00012228356810314864,
      "loss": 0.7381,
      "num_input_tokens_seen": 21782128,
      "step": 10700
    },
    {
      "epoch": 46.51413189771198,
      "grad_norm": 1.6900908946990967,
      "learning_rate": 0.0001217161238900369,
      "loss": 0.74,
      "num_input_tokens_seen": 21986000,
      "step": 10800
    },
    {
      "epoch": 46.94481830417227,
      "grad_norm": 2.891101837158203,
      "learning_rate": 0.00012115650656307654,
      "loss": 0.7576,
      "num_input_tokens_seen": 22187984,
      "step": 10900
    },
    {
      "epoch": 47.37550471063257,
      "grad_norm": 2.4231576919555664,
      "learning_rate": 0.00012060453783110546,
      "loss": 0.7074,
      "num_input_tokens_seen": 22392936,
      "step": 11000
    },
    {
      "epoch": 47.37550471063257,
      "eval_BLEU": 30.6398072295773,
      "eval_chrF": 73.06028054092688,
      "eval_loss": 0.6380701661109924,
      "eval_runtime": 3920.2454,
      "eval_samples_per_second": 7.581,
      "eval_steps_per_second": 1.895,
      "num_input_tokens_seen": 22392936,
      "step": 11000
    },
    {
      "epoch": 47.806191117092865,
      "grad_norm": 2.9203901290893555,
      "learning_rate": 0.00012006004503753285,
      "loss": 0.7487,
      "num_input_tokens_seen": 22596104,
      "step": 11100
    },
    {
      "epoch": 48.23687752355316,
      "grad_norm": 1.2113069295883179,
      "learning_rate": 0.00011952286093343937,
      "loss": 0.7776,
      "num_input_tokens_seen": 22800000,
      "step": 11200
    },
    {
      "epoch": 48.66756393001346,
      "grad_norm": 1.7675807476043701,
      "learning_rate": 0.00011899282346174592,
      "loss": 0.7241,
      "num_input_tokens_seen": 23003040,
      "step": 11300
    },
    {
      "epoch": 49.098250336473754,
      "grad_norm": 1.3789281845092773,
      "learning_rate": 0.00011846977555181847,
      "loss": 0.6926,
      "num_input_tokens_seen": 23206520,
      "step": 11400
    },
    {
      "epoch": 49.52893674293405,
      "grad_norm": 2.728402614593506,
      "learning_rate": 0.00011795356492391772,
      "loss": 0.7069,
      "num_input_tokens_seen": 23409912,
      "step": 11500
    },
    {
      "epoch": 49.959623149394346,
      "grad_norm": 2.028895139694214,
      "learning_rate": 0.0001174440439029407,
      "loss": 0.7383,
      "num_input_tokens_seen": 23612536,
      "step": 11600
    },
    {
      "epoch": 50.39030955585464,
      "grad_norm": 2.3092520236968994,
      "learning_rate": 0.00011694106924093723,
      "loss": 0.6871,
      "num_input_tokens_seen": 23818096,
      "step": 11700
    },
    {
      "epoch": 50.82099596231494,
      "grad_norm": 2.581726551055908,
      "learning_rate": 0.0001164445019479164,
      "loss": 0.7107,
      "num_input_tokens_seen": 24021328,
      "step": 11800
    },
    {
      "epoch": 51.251682368775235,
      "grad_norm": 1.566662073135376,
      "learning_rate": 0.0001159542071304897,
      "loss": 0.7312,
      "num_input_tokens_seen": 24224488,
      "step": 11900
    },
    {
      "epoch": 51.68236877523553,
      "grad_norm": 1.681511402130127,
      "learning_rate": 0.00011547005383792517,
      "loss": 0.6899,
      "num_input_tokens_seen": 24428008,
      "step": 12000
    },
    {
      "epoch": 51.68236877523553,
      "eval_BLEU": 50.797297077157204,
      "eval_chrF": 76.56202287209807,
      "eval_loss": 0.5994001030921936,
      "eval_runtime": 2160.1577,
      "eval_samples_per_second": 13.758,
      "eval_steps_per_second": 3.44,
      "num_input_tokens_seen": 24428008,
      "step": 12000
    },
    {
      "epoch": 52.11305518169583,
      "grad_norm": 2.1072254180908203,
      "learning_rate": 0.00011499191491521382,
      "loss": 0.6639,
      "num_input_tokens_seen": 24631744,
      "step": 12100
    },
    {
      "epoch": 52.543741588156124,
      "grad_norm": 1.825735330581665,
      "learning_rate": 0.00011451966686277364,
      "loss": 0.6877,
      "num_input_tokens_seen": 24835392,
      "step": 12200
    },
    {
      "epoch": 52.97442799461642,
      "grad_norm": 2.5447723865509033,
      "learning_rate": 0.00011405318970244021,
      "loss": 0.7196,
      "num_input_tokens_seen": 25037472,
      "step": 12300
    },
    {
      "epoch": 53.405114401076716,
      "grad_norm": 2.2674036026000977,
      "learning_rate": 0.00011359236684941297,
      "loss": 0.6643,
      "num_input_tokens_seen": 25242360,
      "step": 12400
    },
    {
      "epoch": 53.83580080753701,
      "grad_norm": 2.8102164268493652,
      "learning_rate": 0.00011313708498984761,
      "loss": 0.6706,
      "num_input_tokens_seen": 25446136,
      "step": 12500
    },
    {
      "epoch": 54.26648721399731,
      "grad_norm": 1.9402508735656738,
      "learning_rate": 0.0001126872339638022,
      "loss": 0.693,
      "num_input_tokens_seen": 25648944,
      "step": 12600
    },
    {
      "epoch": 54.697173620457605,
      "grad_norm": 2.0698304176330566,
      "learning_rate": 0.00011224270665326275,
      "loss": 0.6618,
      "num_input_tokens_seen": 25852656,
      "step": 12700
    },
    {
      "epoch": 55.1278600269179,
      "grad_norm": 1.7410495281219482,
      "learning_rate": 0.0001118033988749895,
      "loss": 0.6307,
      "num_input_tokens_seen": 26056680,
      "step": 12800
    },
    {
      "epoch": 55.5585464333782,
      "grad_norm": 2.430104970932007,
      "learning_rate": 0.00011136920927794092,
      "loss": 0.6513,
      "num_input_tokens_seen": 26260296,
      "step": 12900
    },
    {
      "epoch": 55.98923283983849,
      "grad_norm": 2.373399019241333,
      "learning_rate": 0.00011094003924504583,
      "loss": 0.7137,
      "num_input_tokens_seen": 26462472,
      "step": 13000
    },
    {
      "epoch": 55.98923283983849,
      "eval_BLEU": 50.41471800894491,
      "eval_chrF": 77.33888792856165,
      "eval_loss": 0.5547034740447998,
      "eval_runtime": 2283.0326,
      "eval_samples_per_second": 13.017,
      "eval_steps_per_second": 3.254,
      "num_input_tokens_seen": 26462472,
      "step": 13000
    },
    {
      "epoch": 56.41991924629879,
      "grad_norm": 3.2287402153015137,
      "learning_rate": 0.00011051579279910753,
      "loss": 0.6308,
      "num_input_tokens_seen": 26666464,
      "step": 13100
    },
    {
      "epoch": 56.850605652759086,
      "grad_norm": 3.3205058574676514,
      "learning_rate": 0.00011009637651263606,
      "loss": 0.6726,
      "num_input_tokens_seen": 26869664,
      "step": 13200
    },
    {
      "epoch": 57.28129205921938,
      "grad_norm": 1.7785649299621582,
      "learning_rate": 0.00010968169942141635,
      "loss": 0.6255,
      "num_input_tokens_seen": 27074104,
      "step": 13300
    },
    {
      "epoch": 57.71197846567968,
      "grad_norm": 1.7982834577560425,
      "learning_rate": 0.0001092716729416306,
      "loss": 0.6462,
      "num_input_tokens_seen": 27277304,
      "step": 13400
    },
    {
      "epoch": 58.142664872139974,
      "grad_norm": 2.0695810317993164,
      "learning_rate": 0.00010886621079036347,
      "loss": 0.6178,
      "num_input_tokens_seen": 27480976,
      "step": 13500
    },
    {
      "epoch": 58.57335127860027,
      "grad_norm": 1.9080177545547485,
      "learning_rate": 0.00010846522890932808,
      "loss": 0.6275,
      "num_input_tokens_seen": 27684048,
      "step": 13600
    },
    {
      "epoch": 59.00403768506057,
      "grad_norm": 1.6623188257217407,
      "learning_rate": 0.00010806864539165984,
      "loss": 0.707,
      "num_input_tokens_seen": 27886504,
      "step": 13700
    },
    {
      "epoch": 59.43472409152086,
      "grad_norm": 1.559431791305542,
      "learning_rate": 0.0001076763804116331,
      "loss": 0.6133,
      "num_input_tokens_seen": 28090088,
      "step": 13800
    },
    {
      "epoch": 59.86541049798116,
      "grad_norm": 1.7218066453933716,
      "learning_rate": 0.00010728835615716402,
      "loss": 0.6309,
      "num_input_tokens_seen": 28293256,
      "step": 13900
    },
    {
      "epoch": 60.296096904441455,
      "grad_norm": 2.713700294494629,
      "learning_rate": 0.00010690449676496977,
      "loss": 0.5975,
      "num_input_tokens_seen": 28498656,
      "step": 14000
    },
    {
      "epoch": 60.296096904441455,
      "eval_BLEU": 63.25294425090161,
      "eval_chrF": 79.30330672874118,
      "eval_loss": 0.5168054103851318,
      "eval_runtime": 2004.774,
      "eval_samples_per_second": 14.824,
      "eval_steps_per_second": 3.706,
      "num_input_tokens_seen": 28498656,
      "step": 14000
    },
    {
      "epoch": 60.72678331090175,
      "grad_norm": 1.7807828187942505,
      "learning_rate": 0.0001065247282582615,
      "loss": 0.6225,
      "num_input_tokens_seen": 28702112,
      "step": 14100
    },
    {
      "epoch": 61.15746971736205,
      "grad_norm": 1.9338946342468262,
      "learning_rate": 0.00010614897848685506,
      "loss": 0.5794,
      "num_input_tokens_seen": 28905848,
      "step": 14200
    },
    {
      "epoch": 61.588156123822344,
      "grad_norm": 2.3524410724639893,
      "learning_rate": 0.00010577717706958901,
      "loss": 0.6123,
      "num_input_tokens_seen": 29109304,
      "step": 14300
    },
    {
      "epoch": 62.01884253028264,
      "grad_norm": 1.1010820865631104,
      "learning_rate": 0.00010540925533894598,
      "loss": 0.6765,
      "num_input_tokens_seen": 29312784,
      "step": 14400
    },
    {
      "epoch": 62.44952893674294,
      "grad_norm": 1.5284168720245361,
      "learning_rate": 0.00010504514628777804,
      "loss": 0.6039,
      "num_input_tokens_seen": 29516144,
      "step": 14500
    },
    {
      "epoch": 62.88021534320323,
      "grad_norm": 1.4796085357666016,
      "learning_rate": 0.00010468478451804274,
      "loss": 0.6062,
      "num_input_tokens_seen": 29718480,
      "step": 14600
    },
    {
      "epoch": 63.31090174966353,
      "grad_norm": 2.023346185684204,
      "learning_rate": 0.00010432810619146023,
      "loss": 0.5732,
      "num_input_tokens_seen": 29923176,
      "step": 14700
    },
    {
      "epoch": 63.741588156123825,
      "grad_norm": 1.840063214302063,
      "learning_rate": 0.00010397504898200727,
      "loss": 0.6043,
      "num_input_tokens_seen": 30126568,
      "step": 14800
    },
    {
      "epoch": 64.17227456258412,
      "grad_norm": 2.464087724685669,
      "learning_rate": 0.00010362555203016795,
      "loss": 0.5863,
      "num_input_tokens_seen": 30330816,
      "step": 14900
    },
    {
      "epoch": 64.60296096904442,
      "grad_norm": 2.789992094039917,
      "learning_rate": 0.00010327955589886444,
      "loss": 0.5924,
      "num_input_tokens_seen": 30534208,
      "step": 15000
    },
    {
      "epoch": 64.60296096904442,
      "eval_BLEU": 49.66565320819983,
      "eval_chrF": 79.14618653408917,
      "eval_loss": 0.48798251152038574,
      "eval_runtime": 2268.8213,
      "eval_samples_per_second": 13.099,
      "eval_steps_per_second": 3.275,
      "num_input_tokens_seen": 30534208,
      "step": 15000
    },
    {
      "epoch": 65.03364737550471,
      "grad_norm": 1.6696416139602661,
      "learning_rate": 0.00010293700253099577,
      "loss": 0.6286,
      "num_input_tokens_seen": 30737688,
      "step": 15100
    },
    {
      "epoch": 65.46433378196501,
      "grad_norm": 1.531753659248352,
      "learning_rate": 0.00010259783520851542,
      "loss": 0.5744,
      "num_input_tokens_seen": 30941208,
      "step": 15200
    },
    {
      "epoch": 65.8950201884253,
      "grad_norm": 1.921770691871643,
      "learning_rate": 0.00010226199851298272,
      "loss": 0.5977,
      "num_input_tokens_seen": 31143512,
      "step": 15300
    },
    {
      "epoch": 66.3257065948856,
      "grad_norm": 1.5567518472671509,
      "learning_rate": 0.00010192943828752511,
      "loss": 0.5421,
      "num_input_tokens_seen": 31348112,
      "step": 15400
    },
    {
      "epoch": 66.7563930013459,
      "grad_norm": 1.8409467935562134,
      "learning_rate": 0.00010160010160015241,
      "loss": 0.5701,
      "num_input_tokens_seen": 31552112,
      "step": 15500
    },
    {
      "epoch": 67.1870794078062,
      "grad_norm": 2.776550054550171,
      "learning_rate": 0.00010127393670836667,
      "loss": 0.6092,
      "num_input_tokens_seen": 31755656,
      "step": 15600
    },
    {
      "epoch": 67.61776581426649,
      "grad_norm": 2.2765040397644043,
      "learning_rate": 0.00010095089302501375,
      "loss": 0.5732,
      "num_input_tokens_seen": 31959528,
      "step": 15700
    },
    {
      "epoch": 68.04845222072679,
      "grad_norm": 1.7563849687576294,
      "learning_rate": 0.00010063092108532553,
      "loss": 0.5762,
      "num_input_tokens_seen": 32162432,
      "step": 15800
    },
    {
      "epoch": 68.47913862718708,
      "grad_norm": 1.834962248802185,
      "learning_rate": 0.00010031397251510383,
      "loss": 0.5464,
      "num_input_tokens_seen": 32365664,
      "step": 15900
    },
    {
      "epoch": 68.90982503364738,
      "grad_norm": 1.5346757173538208,
      "learning_rate": 0.0001,
      "loss": 0.595,
      "num_input_tokens_seen": 32568384,
      "step": 16000
    },
    {
      "epoch": 68.90982503364738,
      "eval_BLEU": 54.5179568361245,
      "eval_chrF": 79.99992155848041,
      "eval_loss": 0.4622350335121155,
      "eval_runtime": 2235.8476,
      "eval_samples_per_second": 13.292,
      "eval_steps_per_second": 3.323,
      "num_input_tokens_seen": 32568384,
      "step": 16000
    },
    {
      "epoch": 69.34051144010768,
      "grad_norm": 1.9430309534072876,
      "learning_rate": 9.968895725584536e-05,
      "loss": 0.5199,
      "num_input_tokens_seen": 32772920,
      "step": 16100
    },
    {
      "epoch": 69.77119784656797,
      "grad_norm": 2.115729808807373,
      "learning_rate": 9.938079899999067e-05,
      "loss": 0.5673,
      "num_input_tokens_seen": 32976248,
      "step": 16200
    },
    {
      "epoch": 70.20188425302827,
      "grad_norm": 2.8067033290863037,
      "learning_rate": 9.9075480923614e-05,
      "loss": 0.5886,
      "num_input_tokens_seen": 33180208,
      "step": 16300
    },
    {
      "epoch": 70.63257065948856,
      "grad_norm": 3.5109469890594482,
      "learning_rate": 9.877295966495897e-05,
      "loss": 0.5521,
      "num_input_tokens_seen": 33383856,
      "step": 16400
    },
    {
      "epoch": 71.06325706594886,
      "grad_norm": 1.7607839107513428,
      "learning_rate": 9.847319278346618e-05,
      "loss": 0.5639,
      "num_input_tokens_seen": 33587080,
      "step": 16500
    },
    {
      "epoch": 71.49394347240916,
      "grad_norm": 1.871153473854065,
      "learning_rate": 9.81761387347632e-05,
      "loss": 0.5454,
      "num_input_tokens_seen": 33790472,
      "step": 16600
    },
    {
      "epoch": 71.92462987886945,
      "grad_norm": 1.7990353107452393,
      "learning_rate": 9.788175684647928e-05,
      "loss": 0.556,
      "num_input_tokens_seen": 33993000,
      "step": 16700
    },
    {
      "epoch": 72.35531628532975,
      "grad_norm": 2.087336778640747,
      "learning_rate": 9.759000729485331e-05,
      "loss": 0.509,
      "num_input_tokens_seen": 34197504,
      "step": 16800
    },
    {
      "epoch": 72.78600269179005,
      "grad_norm": 1.9567492008209229,
      "learning_rate": 9.730085108210398e-05,
      "loss": 0.5457,
      "num_input_tokens_seen": 34401056,
      "step": 16900
    },
    {
      "epoch": 73.21668909825034,
      "grad_norm": 2.629559278488159,
      "learning_rate": 9.70142500145332e-05,
      "loss": 0.5995,
      "num_input_tokens_seen": 34603000,
      "step": 17000
    },
    {
      "epoch": 73.21668909825034,
      "eval_BLEU": 65.65969138163035,
      "eval_chrF": 81.08549517782136,
      "eval_loss": 0.43571653962135315,
      "eval_runtime": 2192.6868,
      "eval_samples_per_second": 13.554,
      "eval_steps_per_second": 3.389,
      "num_input_tokens_seen": 34603000,
      "step": 17000
    },
    {
      "epoch": 73.64737550471064,
      "grad_norm": 2.824648141860962,
      "learning_rate": 9.673016668133489e-05,
      "loss": 0.5426,
      "num_input_tokens_seen": 34806456,
      "step": 17100
    },
    {
      "epoch": 74.07806191117093,
      "grad_norm": 1.7349662780761719,
      "learning_rate": 9.644856443408244e-05,
      "loss": 0.5093,
      "num_input_tokens_seen": 35011728,
      "step": 17200
    },
    {
      "epoch": 74.50874831763123,
      "grad_norm": 1.8855921030044556,
      "learning_rate": 9.616940736686902e-05,
      "loss": 0.5377,
      "num_input_tokens_seen": 35215184,
      "step": 17300
    },
    {
      "epoch": 74.93943472409153,
      "grad_norm": 1.7380480766296387,
      "learning_rate": 9.589266029707684e-05,
      "loss": 0.5364,
      "num_input_tokens_seen": 35417616,
      "step": 17400
    },
    {
      "epoch": 75.37012113055182,
      "grad_norm": 1.909057378768921,
      "learning_rate": 9.561828874675149e-05,
      "loss": 0.5022,
      "num_input_tokens_seen": 35622632,
      "step": 17500
    },
    {
      "epoch": 75.80080753701212,
      "grad_norm": 1.7569183111190796,
      "learning_rate": 9.534625892455923e-05,
      "loss": 0.5376,
      "num_input_tokens_seen": 35826056,
      "step": 17600
    },
    {
      "epoch": 76.23149394347242,
      "grad_norm": 1.6262644529342651,
      "learning_rate": 9.507653770830567e-05,
      "loss": 0.5755,
      "num_input_tokens_seen": 36028800,
      "step": 17700
    },
    {
      "epoch": 76.66218034993271,
      "grad_norm": 1.2700988054275513,
      "learning_rate": 9.480909262799545e-05,
      "loss": 0.5175,
      "num_input_tokens_seen": 36232992,
      "step": 17800
    },
    {
      "epoch": 77.09286675639301,
      "grad_norm": 1.6186245679855347,
      "learning_rate": 9.45438918494131e-05,
      "loss": 0.4983,
      "num_input_tokens_seen": 36436376,
      "step": 17900
    },
    {
      "epoch": 77.5235531628533,
      "grad_norm": 2.2780649662017822,
      "learning_rate": 9.428090415820635e-05,
      "loss": 0.5108,
      "num_input_tokens_seen": 36640184,
      "step": 18000
    },
    {
      "epoch": 77.5235531628533,
      "eval_BLEU": 61.567305669135,
      "eval_chrF": 82.00210433026105,
      "eval_loss": 0.4160268008708954,
      "eval_runtime": 2133.4064,
      "eval_samples_per_second": 13.93,
      "eval_steps_per_second": 3.483,
      "num_input_tokens_seen": 36640184,
      "step": 18000
    },
    {
      "epoch": 77.9542395693136,
      "grad_norm": 2.2136240005493164,
      "learning_rate": 9.402009894445369e-05,
      "loss": 0.5374,
      "num_input_tokens_seen": 36842552,
      "step": 18100
    },
    {
      "epoch": 78.3849259757739,
      "grad_norm": 2.281521797180176,
      "learning_rate": 9.376144618769909e-05,
      "loss": 0.4981,
      "num_input_tokens_seen": 37047376,
      "step": 18200
    },
    {
      "epoch": 78.81561238223419,
      "grad_norm": 2.6163454055786133,
      "learning_rate": 9.350491644243689e-05,
      "loss": 0.5205,
      "num_input_tokens_seen": 37250864,
      "step": 18300
    },
    {
      "epoch": 79.24629878869449,
      "grad_norm": 1.9647883176803589,
      "learning_rate": 9.325048082403138e-05,
      "loss": 0.5316,
      "num_input_tokens_seen": 37454184,
      "step": 18400
    },
    {
      "epoch": 79.67698519515478,
      "grad_norm": 1.1027621030807495,
      "learning_rate": 9.299811099505544e-05,
      "loss": 0.5146,
      "num_input_tokens_seen": 37657704,
      "step": 18500
    },
    {
      "epoch": 80.10767160161507,
      "grad_norm": 1.6940577030181885,
      "learning_rate": 9.274777915203365e-05,
      "loss": 0.4904,
      "num_input_tokens_seen": 37861696,
      "step": 18600
    },
    {
      "epoch": 80.53835800807536,
      "grad_norm": 1.6934322118759155,
      "learning_rate": 9.249945801257606e-05,
      "loss": 0.5018,
      "num_input_tokens_seen": 38064992,
      "step": 18700
    },
    {
      "epoch": 80.96904441453566,
      "grad_norm": 2.722580671310425,
      "learning_rate": 9.225312080288851e-05,
      "loss": 0.5384,
      "num_input_tokens_seen": 38267200,
      "step": 18800
    },
    {
      "epoch": 81.39973082099596,
      "grad_norm": 2.0058953762054443,
      "learning_rate": 9.200874124564724e-05,
      "loss": 0.4853,
      "num_input_tokens_seen": 38472056,
      "step": 18900
    },
    {
      "epoch": 81.83041722745625,
      "grad_norm": 2.4916975498199463,
      "learning_rate": 9.17662935482247e-05,
      "loss": 0.5049,
      "num_input_tokens_seen": 38675384,
      "step": 19000
    },
    {
      "epoch": 81.83041722745625,
      "eval_BLEU": 65.69281013867682,
      "eval_chrF": 82.35030758460009,
      "eval_loss": 0.4006138741970062,
      "eval_runtime": 2070.5925,
      "eval_samples_per_second": 14.353,
      "eval_steps_per_second": 3.588,
      "num_input_tokens_seen": 38675384,
      "step": 19000
    }
  ],
  "logging_steps": 100,
  "max_steps": 1000000,
  "num_input_tokens_seen": 38675384,
  "num_train_epochs": 4311,
  "save_steps": 1000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 10,
        "early_stopping_threshold": 0.001
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.0138046955841126e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
